{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability for Saltelli\n",
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.utils import write_pickle, read_hdf5_array\n",
    "from SALib.analyze.sobol import analyze\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_base = Path(\n",
    "        \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "    )\n",
    "    # path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"ch hh average consumption\" in act['name']][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 2000\n",
    "    write_dir = path_base / \"lca_model_consumption_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    validation_seed = 7043\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "\n",
    "    iterations = 100 * num_params\n",
    "\n",
    "    gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=100,\n",
    "    )\n",
    "    problem = {\n",
    "        \"num_vars\": num_params,\n",
    "    }\n",
    "    S_dict = {}\n",
    "    for i, step in enumerate(conv.iterations_for_convergence):\n",
    "        print(step)\n",
    "        Y = read_hdf5_array(gsa.filepath_Y).flatten()[:step]\n",
    "        S_dict[step] = analyze(problem, Y, calc_second_order=False, num_resamples=100)\n",
    "    filepath = write_dir / \"arrays\" / \"stability.S.saltelliGsa.{}step{}\".format(\n",
    "        gsa.iterations,conv.iterations_step)\n",
    "    write_pickle(S_dict, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_pc = \"merlin_paper_gsa\"\n",
    "if 'merlin' in which_pc:\n",
    "    path_dask_logs = '/data/user/kim_a/dask_logs'\n",
    "    if not os.path.exists(path_dask_logs):\n",
    "        os.makedirs(path_dask_logs)\n",
    "    cluster = SLURMCluster(cores=8,\n",
    "                           memory=\"80GB\", \n",
    "                           walltime  = '10:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = path_dask_logs,\n",
    "                           log_directory   = path_dask_logs,\n",
    "                           queue=\"daily\",\n",
    "                           ) \n",
    "elif 'local' in which_pc:\n",
    "    cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 80\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.196.21:46363</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.196.21:8787/status' target='_blank'>http://192.168.196.21:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: not connected>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.sensitivity_analysis.correlations import corrcoef_parallel\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.utils import write_pickle\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_worker(iterations_current, seed):\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "    num_params = 10000\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    stability_dir = write_dir / \"stability_intermediate_correlationsGsa\"\n",
    "    \n",
    "    filepath_S = stability_dir / \"step{}.seed{}.pickle\".format(iterations_current, seed)\n",
    "    if not filepath_S.exists():\n",
    "        np.random.rand(seed)\n",
    "        X = np.random.rand(iterations_current, num_params)\n",
    "        Xr = model.rescale(X)\n",
    "        del X\n",
    "        y = model(Xr)\n",
    "        S_dict = corrcoef_parallel(y, Xr)\n",
    "        write_pickle(S_dict, filepath_S)\n",
    "        return S_dict\n",
    "    else:\n",
    "        print(\"{} already exists\".format(filepath_S.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "814\n",
      "1618\n",
      "2422\n",
      "3226\n",
      "4030\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     path_base = Path(\n",
    "#         \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "#     )\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"Food\" in act[\"name\"]][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 500\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    validation_seed = 7043\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "\n",
    "    iterations = 2 * num_params\n",
    "    gsa = CorrelationCoefficients(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        seed=gsa_seed,\n",
    "    )\n",
    "\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=100,\n",
    "    )\n",
    "    num_bootstrap = 10\n",
    "    np.random.seed(gsa_seed)\n",
    "    stability_seeds = np.random.randint(\n",
    "        low=0,\n",
    "        high=2147483647,\n",
    "        size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    "    )\n",
    "    \n",
    "    stability_dir = write_dir / \"stability_intermediate_{}\".format(gsa.gsa_label)\n",
    "    stability_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    istep = 4\n",
    "    i=0\n",
    "    for iterations_current in conv.iterations_for_convergence[::istep]:\n",
    "        print(iterations_current)\n",
    "        for seed in stability_seeds[i,:]:\n",
    "            compute_per_worker(iterations_current, seed)\n",
    "        i += istep\n",
    "#     model_evals = []\n",
    "#     model_evals_all = []\n",
    "#     task_per_worker = dask.delayed(compute_per_worker)\n",
    "#     i=0\n",
    "#     for iterations_current in conv.iterations_for_convergence[::2]:\n",
    "#         if i%16==0 and len(model_evals)>0:\n",
    "#             print(len(model_evals))\n",
    "#             model_evals_all.append(model_evals)\n",
    "#             model_evals = []\n",
    "#         for seed in stability_seeds[i,:]:\n",
    "#             filepath_S = stability_dir / \"step{}.seed{}.pickle\".format(iterations_current, seed)\n",
    "#             if not filepath_S.exists():\n",
    "#                 model_eval = task_per_worker(iterations_current, seed)\n",
    "#                 model_evals.append(model_eval)\n",
    "#             else:\n",
    "#                 print(\"{} already exists\".format(filepath_S.name))\n",
    "#         i += 2\n",
    "        \n",
    "    model_evals_all.append(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for model_evals in model_evals_all:\n",
    "#     print(len(model_evals))\n",
    "#     dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
