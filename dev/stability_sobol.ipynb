{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.sensitivity_analysis.saltelli_sobol import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read X and Y\n",
    "num_params = 10000\n",
    "iter_salt = 40*num_params\n",
    "gsa = setup_salt(num_params, iter_salt, setup_lca_model_paper)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 10\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,10) into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,10) into shape (10)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def sobol_first_order(A, AB, B):\n",
    "    \"\"\"First order estimator normalized by sample variance.\"\"\"\n",
    "#     return np.mean(B * (AB - A), axis=0) / np.var(np.r_[A, B], axis=0)\n",
    "    return np.mean(B * (AB - A), axis=0) # in the paper and in SALib\n",
    "    \n",
    "# def sobol_indices_stability(Y, num_params, iterations_for_convergence, num_bootstrap):    \n",
    "for iterations_current in conv.iterations_for_convergence:\n",
    "    iterations_per_param = iterations_current // (num_params+2)\n",
    "    print(iterations_per_param)\n",
    "#     Ycurrent = Y[:iterations_current]\n",
    "    A, B, AB = separate_output_values(Y, num_params)\n",
    "    choice = np.random.randint(iterations_per_param, size=(iterations_per_param, num_bootstrap))\n",
    "    A_choice = A[choice]\n",
    "    B_choice = B[choice]\n",
    "    first = np.zeros((num_bootstrap,num_params))\n",
    "    total = np.zeros((num_bootstrap,num_params))\n",
    "    for j in range(num_params):\n",
    "        print(j)\n",
    "        first[:,j] = sobol_first_order(A_choice, AB[choice, j], B_choice)\n",
    "        total[:,j] = sobol_total_order(A_choice, AB[choice, j], B_choice)\n",
    "    S_dict = {\n",
    "        iterations_current: {\n",
    "            \"First order\": first,\n",
    "            \"Total order\": total,\n",
    "        }\n",
    "    }\n",
    "#     return S_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177],\n",
       "       [10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177,\n",
       "        10.04216177, 10.04216177, 10.04216177, 10.04216177, 10.04216177]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobol_first_order(A_choice, AB[choice, j], B_choice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373],\n",
       "        [252.28081373]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB[choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.iterations_min, conv.iterations_least_common_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    S_dict_stability = {}\n",
    "    for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "        S_array = np.zeros([0,num_params])\n",
    "        print(\"{}\".format(iterations_current))\n",
    "        for j in range(num_bootstrap):\n",
    "            stability_seed = stability_seeds[i,j]\n",
    "            np.random.seed(stability_seed)\n",
    "            \n",
    "            \n",
    "            choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "            Y_current = Y[choice]\n",
    "            S_current = corrcoef_parallel_stability_spearman(Y_current, X_current)\n",
    "            S_array = np.vstack([S_array, S_current])\n",
    "        S_dict = {iterations_current: {\"spearman\": S_array}}\n",
    "        S_dict_stability.update(S_dict)\n",
    "    write_pickle(S_dict_stability, filepath_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
