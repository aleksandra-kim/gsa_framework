{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import Morris4\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "\n",
    "    # 1. Models\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 2000\n",
    "    write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "    model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "    gsa_seed = 3407\n",
    "    validation_seed = 7043\n",
    "    num_influential_validation = 2*num_influential\n",
    "\n",
    "    fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "    # TODO Choose which GSA to perform\n",
    "    flag_sobol = 0\n",
    "    flag_correlation = 0\n",
    "    flag_xgboost = 0\n",
    "    flag_delta = 1\n",
    "\n",
    "    if flag_sobol:\n",
    "        iterations = 100 * num_params\n",
    "        gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "        # S_dict = gsa.generate_gsa_indices()\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "#         gsa.plot_sa_results(\n",
    "#             S_dict,\n",
    "#             S_dict_analytical=model.S_dict_analytical,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"TotalIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(total, num_influential_validation, tag=tag)\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "        \n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n",
    "\n",
    "    if flag_correlation:\n",
    "        iterations = 4 * num_params\n",
    "        gsa = CorrelationCoefficients(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        pearson = S_dict[\"pearson\"]\n",
    "        spearman = S_dict[\"spearman\"]\n",
    "#         gsa.plot_sa_results(S_dict, S_boolean=model.S_boolean, fig_format=fig_format)\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"SpearmanIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(\n",
    "            spearman, num_influential_validation, tag=tag\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(\n",
    "#             parameter_inds=parameter_inds,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "    if flag_delta:\n",
    "        iterations = 8 * num_params\n",
    "        num_resamples = 1\n",
    "        gsa = DeltaMoment(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            num_resamples=num_resamples,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        S_dict.pop('delta_conf')\n",
    "        delta = S_dict['delta']\n",
    "        gsa.plot_sa_results(\n",
    "            S_dict,\n",
    "            S_boolean=model.S_boolean,\n",
    "            fig_format=fig_format,\n",
    "        )\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"DeltaIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(\n",
    "            delta, num_influential_validation, tag=tag\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    if flag_xgboost:\n",
    "        if num_params == 1000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.35,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 5000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 10000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        iterations = 10000\n",
    "        gsa = GradientBoosting(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "            tuning_parameters=tuning_parameters,\n",
    "            num_boost_round=num_boost_round,\n",
    "            xgb_model=None,\n",
    "        )\n",
    "        S_dict, r2, ev = gsa.perform_gsa(flag_save_S_dict=True, return_stats=True)\n",
    "        print(r2, ev)\n",
    "        # fscores = S_dict[\"fscores\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_boolean=model.S_boolean,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "        #\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"FscoresIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(\n",
    "        #     fscores, num_influential_validation, tag=tag\n",
    "        # )\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "        # conv = Convergence(\n",
    "        #     gsa.filepath_Y,\n",
    "        #     gsa.num_params,\n",
    "        #     gsa.generate_gsa_indices,\n",
    "        #     gsa.gsa_label,\n",
    "        #     write_dir,\n",
    "        #     num_steps=100,\n",
    "        # )\n",
    "        # conv.run_convergence(\n",
    "        #     parameter_inds=parameter_inds,\n",
    "        #     fig_format=fig_format,\n",
    "        # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.sensitivity_analysis.correlations import corrcoef_parallel_stability_spearman\n",
    "from gsa_framework.test_functions import Morris4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "# read X and Y\n",
    "num_params = 1000\n",
    "num_influential = num_params // 100\n",
    "write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "gsa_seed = 3407\n",
    "fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "iter_corr = 4*num_params\n",
    "gsa = CorrelationCoefficients(\n",
    "    iterations=iter_corr,\n",
    "    model=model,\n",
    "    write_dir=write_dir,\n",
    "    seed=gsa_seed,\n",
    ")\n",
    "\n",
    "X_rescaled = read_hdf5_array(gsa.filepath_X_rescaled)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "write_dir_stability = gsa.write_dir / 'stability_intermediate_{}'.format(gsa.gsa_label)\n",
    "write_dir_stability.mkdir(parents=True, exist_ok=True)\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    S_dict_stability = {}\n",
    "    for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "        S_array = np.zeros([0,num_params])\n",
    "        print(\"{}\".format(iterations_current))\n",
    "        filename_S_current = \"S.{}Step{}.{}.{}.pickle\".format(iterations_current,conv.iterations_step,num_bootstrap,gsa.seed)\n",
    "        filepath_S_current = write_dir_stability / filename_S_current\n",
    "        if filepath_S_current.exists():\n",
    "            print(\"--> {} already exists\".format(filename_S_current))\n",
    "            S_dict = read_pickle(filepath_S_current)\n",
    "        else:\n",
    "            for j in range(num_bootstrap):\n",
    "                stability_seed = stability_seeds[i,j]\n",
    "                np.random.seed(stability_seed)\n",
    "                choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "                Y_current = Y[choice]\n",
    "                X_current = X_rescaled[choice,:]\n",
    "                S_current = corrcoef_parallel_stability_spearman(Y_current, X_current)['spearman']\n",
    "                S_array = np.vstack([S_array, S_current])\n",
    "            S_dict = {iterations_current: {\"spearman\": S_array}}\n",
    "            write_pickle(S_dict, filepath_S_current)\n",
    "        S_dict_stability.update(S_dict)\n",
    "    write_pickle(S_dict_stability, filepath_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from pathlib import Path\n",
    "import os\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_pc = \"merlin_paper_gsa\"\n",
    "if 'merlin' in which_pc:\n",
    "    path_dask_logs = Path('/data/user/kim_a/dask_logs')\n",
    "    path_dask_logs.mkdir(parents=True, exist_ok=True)\n",
    "    cluster = SLURMCluster(cores     = 8,\n",
    "                           memory    =\"60GB\", \n",
    "                           walltime  = '10:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = path_dask_logs.as_posix(),\n",
    "                           log_directory   = path_dask_logs.as_posix(),\n",
    "                           queue=\"daily\",\n",
    "                           ) \n",
    "elif 'local' in which_pc:\n",
    "    cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 60\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.196.29:39243</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.196.29:8787/status' target='_blank'>http://192.168.196.29:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.196.29:39243' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability delta moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.test_functions import Morris4\n",
    "from gsa_framework.sensitivity_analysis.delta_moment import delta_moment_parallel_stability\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_worker_delt(num_params, iterations_current, stability_seed):\n",
    "    iter_delt = 8*num_params\n",
    "    gsa_delt = setup_delt(num_params, iter_delt, setup_morris4_model)\n",
    "    filepath_Y = gsa_delt.write_dir_stability / \"Y.step{}.seed{}.pickle\".format(iterations_current, stability_seed)\n",
    "    Y = read_pickle(filepath_Y).flatten()\n",
    "    np.random.seed(gsa_delt.seed)\n",
    "    X = np.random.rand(iter_delt, num_params)\n",
    "    np.random.seed(stability_seed)\n",
    "    choice = np.random.choice(np.arange(iter_delt), iterations_current, replace=False)\n",
    "    Xr = gsa_delt.model.rescale(X[choice, :])\n",
    "    del X\n",
    "    filepath_S = gsa_delt.write_dir_stability / \"S.step{}.seed{}.pickle\".format(iterations_current, stability_seed)\n",
    "    if not filepath_S.exists():\n",
    "        S_dict = delta_moment_parallel_stability(\n",
    "            Y, Xr, num_resamples=gsa_delt.num_resamples, seed=stability_seed\n",
    "        )\n",
    "        write_pickle(S_dict, filepath_S)\n",
    "    else:\n",
    "        print(\"{} already exists\".format(filepath_S.name))\n",
    "        S_dict = read_pickle(filepath_S)\n",
    "    \n",
    "    return S_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 1000\n",
    "iter_delt = 8*num_params\n",
    "gsa_delt = setup_delt(num_params, iter_delt, setup_morris4_model)\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "option = 'delta'\n",
    "if option=='delta':\n",
    "    gsa = gsa_delt\n",
    "    compute_per_worker = compute_per_worker_delt\n",
    "elif option=='xgboost':\n",
    "    gsa = gsa_xgbo\n",
    "    compute_per_worker = compute_per_worker_xgbo\n",
    "\n",
    "task_per_worker = dask.delayed(compute_per_worker)\n",
    "# task_per_worker = compute_per_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir_convergence,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")\n",
    "\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "model_evals = []\n",
    "for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "    model_evals_bootstrap_j = []\n",
    "    for j in range(num_bootstrap):\n",
    "        stability_seed = stability_seeds[i,j]\n",
    "        np.random.seed(stability_seed)\n",
    "        choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "        # Write Y\n",
    "        filepath_Y_ij = gsa.write_dir_stability / \"Y.step{}.seed{}.pickle\".format(iterations_current, stability_seed)\n",
    "        if not filepath_Y_ij.exists():\n",
    "            Y_ij = Y[choice]\n",
    "            write_pickle(Y_ij, filepath_Y_ij)\n",
    "        else:\n",
    "#             print(\"{} already exists\".format(filepath_Y_ij.name))  \n",
    "            pass\n",
    "        # Model evals\n",
    "        model_eval = task_per_worker(num_params, iterations_current, stability_seed)\n",
    "        model_evals_bootstrap_j.append(model_eval)\n",
    "    model_evals.append(model_evals_bootstrap_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "daemonic processes are not allowed to have children",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2710\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2712\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2713\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1983\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1986\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             )\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-2affe5f34929>\u001b[0m in \u001b[0;36mcompute_per_worker_delt\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfilepath_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsa_delt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dir_stability\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"S.step{}.seed{}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilepath_S\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         S_dict = delta_moment_parallel_stability(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_resamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgsa_delt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_resamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstability_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n",
      "\u001b[0;32m~/gsa_framework/gsa_framework/sensitivity_analysis/delta_moment.py\u001b[0m in \u001b[0;36mdelta_moment_parallel_stability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[0;32m--> 232\u001b[0;31m     results_delta, results_delta_conf = delta_parallel_stability(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_rescaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_resamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     )\n",
      "\u001b[0;32m~/gsa_framework/gsa_framework/sensitivity_analysis/delta_moment.py\u001b[0m in \u001b[0;36mdelta_parallel_stability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mresults_all_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mresults_all_delta_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpus_needed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         results = pool.starmap(\n\u001b[1;32m    109\u001b[0m             \u001b[0mbias_reduced_delta_many_chunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36mPool\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m'''Returns a process pool object'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0m\u001b[1;32m    120\u001b[0m                     context=self.get_context())\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return self._repopulate_pool_static(self._ctx, self.Process,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inqueue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool_static\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/kim_a/conda-envs/gsa-dev/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                \u001b[0;34m'can only start a process object created by current process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'daemon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: daemonic processes are not allowed to have children"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,model_evals_bootstrap_j in enumerate(model_evals):\n",
    "    print(i)\n",
    "    dask.compute(model_evals_bootstrap_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.test_functions import Morris4\n",
    "from gsa_framework.sensitivity_analysis.delta_moment import delta_moment_parallel_stability\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "# read X and Y\n",
    "num_params = 5000\n",
    "num_influential = num_params // 100\n",
    "write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "gsa_seed = 3407\n",
    "fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "iter_delt = 8*num_params\n",
    "num_resamples = 1\n",
    "gsa = DeltaMoment(\n",
    "    iterations=iter_delt,\n",
    "    model=model,\n",
    "    write_dir=write_dir,\n",
    "    num_resamples=num_resamples,\n",
    "    seed=gsa_seed,\n",
    ")\n",
    "\n",
    "X_rescaled = read_hdf5_array(gsa.filepath_X_rescaled)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "write_dir_stability = gsa.write_dir / 'stability_intermediate_{}'.format(gsa.gsa_label)\n",
    "write_dir_stability.mkdir(parents=True, exist_ok=True)\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "        gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    "    )\n",
    "    filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "    if filepath_S.exists():\n",
    "        print(\"--> {} already exists\".format(filename_S))\n",
    "        S_dict_stability = read_pickle(filepath_S)\n",
    "    else:\n",
    "        S_dict_stability = {}\n",
    "        for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "            S_array = np.zeros([0,num_params])\n",
    "            print(\"{}\".format(iterations_current))\n",
    "            filename_S_current = \"S.{}Step{}.{}.{}.pickle\".format(iterations_current,conv.iterations_step,num_bootstrap,gsa.seed)\n",
    "            filepath_S_current = write_dir_stability / filename_S_current\n",
    "            if filepath_S_current.exists():\n",
    "                print(\"--> {} already exists\".format(filename_S_current))\n",
    "                S_dict = read_pickle(filepath_S_current)\n",
    "            else:\n",
    "                for j in range(num_bootstrap):\n",
    "                    stability_seed = stability_seeds[i,j]\n",
    "                    np.random.seed(stability_seed)\n",
    "                    choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "                    Y_current = Y[choice]\n",
    "                    X_current = X_rescaled[choice,:]\n",
    "                    S_current = delta_moment_parallel_stability(Y_current, X_current, num_resamples=num_resamples)\n",
    "                    S_array = np.vstack([S_array, S_current['delta']])\n",
    "                S_dict = {iterations_current: {\"delta\": S_array}}\n",
    "                write_pickle(S_dict, filepath_S_current)\n",
    "            S_dict_stability.update(S_dict)\n",
    "        write_pickle(S_dict_stability, filepath_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
