{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import Morris4\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "\n",
    "    # 1. Models\n",
    "    num_params = 1000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 2000\n",
    "    write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "    model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "    gsa_seed = 3407\n",
    "    validation_seed = 7043\n",
    "    num_influential_validation = num_influential\n",
    "\n",
    "    fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "    # TODO Choose which GSA to perform\n",
    "    flag_sobol = 0\n",
    "    flag_correlation = 0\n",
    "    flag_xgboost = 0\n",
    "    flag_delta = 1\n",
    "\n",
    "    if flag_sobol:\n",
    "        iterations = 100 * num_params\n",
    "        gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "        # S_dict = gsa.generate_gsa_indices()\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "#         gsa.plot_sa_results(\n",
    "#             S_dict,\n",
    "#             S_dict_analytical=model.S_dict_analytical,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"TotalIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(total, num_influential_validation, tag=tag)\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "        \n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n",
    "\n",
    "    if flag_correlation:\n",
    "        iterations = 4 * num_params\n",
    "        gsa = CorrelationCoefficients(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        pearson = S_dict[\"pearson\"]\n",
    "        spearman = S_dict[\"spearman\"]\n",
    "#         gsa.plot_sa_results(S_dict, S_boolean=model.S_boolean, fig_format=fig_format)\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"SpearmanIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(\n",
    "            spearman, num_influential_validation, tag=tag\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(\n",
    "#             parameter_inds=parameter_inds,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "    if flag_delta:\n",
    "        iterations = 4 * num_params\n",
    "        num_resamples = 1\n",
    "        gsa = DeltaMoment(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            num_resamples=num_resamples,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        S_dict.pop('delta_conf')\n",
    "        gsa.plot_sa_results(\n",
    "            S_dict,\n",
    "            S_boolean=model.S_boolean,\n",
    "            fig_format=fig_format,\n",
    "        )\n",
    "        \n",
    "\n",
    "    if flag_xgboost:\n",
    "        if num_params == 1000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.35,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 5000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 10000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        iterations = 10000\n",
    "        gsa = GradientBoosting(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "            tuning_parameters=tuning_parameters,\n",
    "            num_boost_round=num_boost_round,\n",
    "            xgb_model=None,\n",
    "        )\n",
    "        S_dict, r2, ev = gsa.perform_gsa(flag_save_S_dict=True, return_stats=True)\n",
    "        print(r2, ev)\n",
    "        # fscores = S_dict[\"fscores\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_boolean=model.S_boolean,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "        #\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"FscoresIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(\n",
    "        #     fscores, num_influential_validation, tag=tag\n",
    "        # )\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "        # conv = Convergence(\n",
    "        #     gsa.filepath_Y,\n",
    "        #     gsa.num_params,\n",
    "        #     gsa.generate_gsa_indices,\n",
    "        #     gsa.gsa_label,\n",
    "        #     write_dir,\n",
    "        #     num_steps=100,\n",
    "        # )\n",
    "        # conv.run_convergence(\n",
    "        #     parameter_inds=parameter_inds,\n",
    "        #     fig_format=fig_format,\n",
    "        # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.sensitivity_analysis.correlations import corrcoef_parallel_stability_spearman\n",
    "from gsa_framework.test_functions import Morris4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "# read X and Y\n",
    "num_params = 10000\n",
    "num_influential = num_params // 100\n",
    "write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "gsa_seed = 3407\n",
    "fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "iter_corr = 4*num_params\n",
    "gsa = CorrelationCoefficients(\n",
    "    iterations=iter_corr,\n",
    "    model=model,\n",
    "    write_dir=write_dir,\n",
    "    seed=gsa_seed,\n",
    ")\n",
    "\n",
    "X_rescaled = read_hdf5_array(gsa.filepath_X_rescaled)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "write_dir_stability = gsa.write_dir / 'stability_intermediate_{}'.format(gsa.gsa_label)\n",
    "write_dir_stability.mkdir(parents=True, exist_ok=True)\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "1600\n",
      "2400\n",
      "3200\n",
      "4000\n",
      "4800\n",
      "5600\n",
      "6400\n",
      "7200\n",
      "8000\n",
      "8800\n",
      "9600\n",
      "10400\n",
      "11200\n",
      "12000\n",
      "12800\n",
      "13600\n",
      "14400\n",
      "15200\n",
      "16000\n",
      "16800\n",
      "17600\n",
      "18400\n",
      "19200\n",
      "20000\n",
      "20800\n",
      "21600\n",
      "22400\n",
      "23200\n",
      "24000\n",
      "24800\n",
      "25600\n",
      "26400\n",
      "27200\n",
      "28000\n",
      "28800\n",
      "29600\n",
      "30400\n",
      "31200\n",
      "32000\n",
      "32800\n",
      "33600\n",
      "34400\n",
      "35200\n",
      "36000\n",
      "36800\n",
      "37600\n",
      "38400\n",
      "39200\n",
      "CPU times: user 3h 7min 31s, sys: 2h 7min 5s, total: 5h 14min 37s\n",
      "Wall time: 9h 17min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    S_dict_stability = {}\n",
    "    for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "        S_array = np.zeros([0,num_params])\n",
    "        print(\"{}\".format(iterations_current))\n",
    "        filename_S_current = \"S.{}Step{}.{}.{}.pickle\".format(iterations_current,conv.iterations_step,num_bootstrap,gsa.seed)\n",
    "        filepath_S_current = write_dir_stability / filename_S_current\n",
    "        if filepath_S_current.exists():\n",
    "            print(\"--> {} already exists\".format(filename_S_current))\n",
    "            S_dict = read_pickle(filepath_S_current)\n",
    "        else:\n",
    "            for j in range(num_bootstrap):\n",
    "                stability_seed = stability_seeds[i,j]\n",
    "                np.random.seed(stability_seed)\n",
    "                choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "                Y_current = Y[choice]\n",
    "                X_current = X_rescaled[choice,:]\n",
    "                S_current = corrcoef_parallel_stability_spearman(Y_current, X_current)['spearman']\n",
    "                S_array = np.vstack([S_array, S_current])\n",
    "            S_dict = {iterations_current: {\"spearman\": S_array}}\n",
    "            write_pickle(S_dict, filepath_S_current)\n",
    "        S_dict_stability.update(S_dict)\n",
    "    write_pickle(S_dict_stability, filepath_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.sensitivity_analysis.correlations import corrcoef_parallel_stability_spearman\n",
    "from gsa_framework.test_functions import Morris4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "# read X and Y\n",
    "num_params = 1000\n",
    "num_influential = num_params // 100\n",
    "write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "gsa_seed = 3407\n",
    "fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "iter_corr = 4*num_params\n",
    "gsa = CorrelationCoefficients(\n",
    "    iterations=iter_corr,\n",
    "    model=model,\n",
    "    write_dir=write_dir,\n",
    "    seed=gsa_seed,\n",
    ")\n",
    "\n",
    "X_rescaled = read_hdf5_array(gsa.filepath_X_rescaled)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "write_dir_stability = gsa.write_dir / 'stability_intermediate_{}'.format(gsa.gsa_label)\n",
    "write_dir_stability.mkdir(parents=True, exist_ok=True)\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "160\n",
      "240\n",
      "320\n",
      "400\n",
      "480\n",
      "560\n",
      "640\n",
      "720\n",
      "800\n",
      "880\n",
      "960\n",
      "1040\n",
      "1120\n",
      "1200\n",
      "1280\n",
      "1360\n",
      "1440\n",
      "1520\n",
      "1600\n",
      "1680\n",
      "1760\n",
      "1840\n",
      "1920\n",
      "2000\n",
      "2080\n",
      "2160\n",
      "2240\n",
      "2320\n",
      "2400\n",
      "2480\n",
      "2560\n",
      "2640\n",
      "2720\n",
      "2800\n",
      "2880\n",
      "2960\n",
      "3040\n",
      "3120\n",
      "3200\n",
      "3280\n",
      "3360\n",
      "3440\n",
      "3520\n",
      "3600\n",
      "3680\n",
      "3760\n",
      "3840\n",
      "3920\n",
      "CPU times: user 2min 52s, sys: 7min 6s, total: 9min 59s\n",
      "Wall time: 25min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    S_dict_stability = {}\n",
    "    for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "        S_array = np.zeros([0,num_params])\n",
    "        print(\"{}\".format(iterations_current))\n",
    "        filename_S_current = \"S.{}Step{}.{}.{}.pickle\".format(iterations_current,conv.iterations_step,num_bootstrap,gsa.seed)\n",
    "        filepath_S_current = write_dir_stability / filename_S_current\n",
    "        if filepath_S_current.exists():\n",
    "            print(\"--> {} already exists\".format(filename_S_current))\n",
    "            S_dict = read_pickle(filepath_S_current)\n",
    "        else:\n",
    "            for j in range(num_bootstrap):\n",
    "                stability_seed = stability_seeds[i,j]\n",
    "                np.random.seed(stability_seed)\n",
    "                choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "                Y_current = Y[choice]\n",
    "                X_current = X_rescaled[choice,:]\n",
    "                S_current = corrcoef_parallel_stability_spearman(Y_current, X_current)['spearman']\n",
    "                S_array = np.vstack([S_array, S_current])\n",
    "            S_dict = {iterations_current: {\"spearman\": S_array}}\n",
    "            write_pickle(S_dict, filepath_S_current)\n",
    "        S_dict_stability.update(S_dict)\n",
    "    write_pickle(S_dict_stability, filepath_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setups_paper_gwp import *\n",
    "from copy import deepcopy\n",
    "from gsa_framework.sensitivity_analysis.correlations import corrcoef_parallel_stability_spearman\n",
    "from gsa_framework.test_functions import Morris4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "# read X and Y\n",
    "num_params = 5000\n",
    "num_influential = num_params // 100\n",
    "write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "gsa_seed = 3407\n",
    "fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "iter_corr = 4*num_params\n",
    "gsa = CorrelationCoefficients(\n",
    "    iterations=iter_corr,\n",
    "    model=model,\n",
    "    write_dir=write_dir,\n",
    "    seed=gsa_seed,\n",
    ")\n",
    "\n",
    "X_rescaled = read_hdf5_array(gsa.filepath_X_rescaled)\n",
    "Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "\n",
    "num_steps = 50\n",
    "num_bootstrap = 60\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "\n",
    "write_dir_stability = gsa.write_dir / 'stability_intermediate_{}'.format(gsa.gsa_label)\n",
    "write_dir_stability.mkdir(parents=True, exist_ok=True)\n",
    "# Generate random seeds\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "4000\n",
      "4400\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label, gsa.sampling_label, gsa.iterations, conv.iterations_step, num_bootstrap, gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    S_dict_stability = {}\n",
    "    for i,iterations_current in enumerate(conv.iterations_for_convergence):\n",
    "        S_array = np.zeros([0,num_params])\n",
    "        print(\"{}\".format(iterations_current))\n",
    "        filename_S_current = \"S.{}Step{}.{}.{}.pickle\".format(iterations_current,conv.iterations_step,num_bootstrap,gsa.seed)\n",
    "        filepath_S_current = write_dir_stability / filename_S_current\n",
    "        if filepath_S_current.exists():\n",
    "            print(\"--> {} already exists\".format(filename_S_current))\n",
    "            S_dict = read_pickle(filepath_S_current)\n",
    "        else:\n",
    "            for j in range(num_bootstrap):\n",
    "                stability_seed = stability_seeds[i,j]\n",
    "                np.random.seed(stability_seed)\n",
    "                choice = np.random.choice(np.arange(gsa.iterations), iterations_current, replace=False)\n",
    "                Y_current = Y[choice]\n",
    "                X_current = X_rescaled[choice,:]\n",
    "                S_current = corrcoef_parallel_stability_spearman(Y_current, X_current)['spearman']\n",
    "                S_array = np.vstack([S_array, S_current])\n",
    "            S_dict = {iterations_current: {\"spearman\": S_array}}\n",
    "            write_pickle(S_dict, filepath_S_current)\n",
    "        S_dict_stability.update(S_dict)\n",
    "    write_pickle(S_dict_stability, filepath_S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
