{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import Morris\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.extended_FAST import eFAST\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     path_base = Path(\n",
    "#         \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "#     )\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # 1. Models\n",
    "    num_params = 1000\n",
    "    # num_influential = num_params // 100\n",
    "    num_influential = 100\n",
    "    iterations_validation = 2000\n",
    "    if num_influential == num_params // 100:\n",
    "        write_dir = path_base / \"morris_model_{}_1percent\".format(num_params)\n",
    "    elif num_influential == 100:\n",
    "        write_dir = path_base / \"morris_model_{}_100\".format(num_params)\n",
    "    model = Morris(num_params=num_params, num_influential=num_influential)\n",
    "    gsa_seed = 3407\n",
    "    validation_seed = 7043\n",
    "\n",
    "    fig_format = [\"html\", \"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "    num_params_correlation_plot = 10\n",
    "    parameter_inds = list(range(num_params_correlation_plot)) + list(\n",
    "        range(num_influential, num_influential + num_params_correlation_plot)\n",
    "    )\n",
    "\n",
    "    # TODO Choose which GSA to perform\n",
    "    flag_sobol = 0\n",
    "    flag_correlation = 0\n",
    "    flag_eFAST = 0\n",
    "    flag_xgboost = 1\n",
    "    flag_delta = 0\n",
    "\n",
    "    if flag_sobol:\n",
    "        iterations = 100 * num_params\n",
    "        gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "        # S_dict = gsa.generate_gsa_indices()\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_dict_analytical=model.S_dict_analytical,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"SaltelliTotalIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(total, num_influential, tag=tag)\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "        #\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n",
    "\n",
    "    if flag_correlation:\n",
    "        iterations = 10000  # * num_params\n",
    "        gsa = CorrelationCoefficients(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "#         pearson = S_dict[\"pearson\"]\n",
    "#         spearman = S_dict[\"spearman\"]\n",
    "        # gsa.plot_sa_results(S_dict, S_boolean=model.S_boolean, fig_format=fig_format)\n",
    "\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"SpearmanIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(\n",
    "        #     spearman, num_influential, tag=tag\n",
    "        # )\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(\n",
    "#             parameter_inds=parameter_inds,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "    if flag_eFAST:\n",
    "        iterations = 100 * num_params\n",
    "        M = 2\n",
    "        gsa = eFAST(\n",
    "            M=M, iterations=iterations, model=model, write_dir=write_dir, seed=gsa_seed\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        # S_dict = gsa.generate_gsa_indices()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_dict_analytical=model.S_dict_analytical,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"eFastTotalIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(total, num_influential, tag=tag)\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#             M=M,\n",
    "#         )\n",
    "#         conv.run_convergence(\n",
    "#             parameter_inds=parameter_inds,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "    if flag_xgboost:\n",
    "        if num_params == 1000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.35,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 5000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 10000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        iterations = 10000\n",
    "        gsa = GradientBoosting(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "            tuning_parameters=tuning_parameters,\n",
    "            num_boost_round=num_boost_round,\n",
    "            xgb_model=None,\n",
    "        )\n",
    "        S_dict, r2, ev = gsa.perform_gsa(flag_save_S_dict=True, return_stats=True)\n",
    "        print(r2, ev)\n",
    "        # fscores = S_dict[\"fscores\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_boolean=model.S_boolean,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "        #\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"FscoresIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(\n",
    "        #     fscores, num_influential, tag=tag\n",
    "        # )\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "        # conv = Convergence(\n",
    "        #     gsa.filepath_Y,\n",
    "        #     gsa.num_params,\n",
    "        #     gsa.generate_gsa_indices,\n",
    "        #     gsa.gsa_label,\n",
    "        #     write_dir,\n",
    "        #     num_steps=100,\n",
    "        # )\n",
    "        # conv.run_convergence(\n",
    "        #     parameter_inds=parameter_inds,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "\n",
    "    if flag_delta:\n",
    "        iterations = 30000#2 * num_params\n",
    "        num_resamples = 1\n",
    "        gsa = DeltaMoment(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            num_resamples=num_resamples,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "#         delta = S_dict[\"delta\"]\n",
    "# #         gsa.plot_sa_results(\n",
    "# #             S_dict,\n",
    "# #             S_boolean=model.S_boolean,\n",
    "# #             fig_format=fig_format,\n",
    "# #         )\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=25,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsa.plot_sa_results(\n",
    "    S_dict,\n",
    "    S_boolean=model.S_boolean,\n",
    "    fig_format=fig_format,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import os\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_pc = \"merlin_paper_gsa\"\n",
    "if 'merlin' in which_pc:\n",
    "    path_dask_logs = '/data/user/kim_a/dask_logs'\n",
    "    if not os.path.exists(path_dask_logs):\n",
    "        os.makedirs(path_dask_logs)\n",
    "    cluster = SLURMCluster(cores     = 8,\n",
    "                           processes = 3,\n",
    "                           memory    =\"90GB\", \n",
    "                           walltime  = '20:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = path_dask_logs,\n",
    "                           log_directory   = path_dask_logs,\n",
    "                           queue=\"daily\",\n",
    "                           ) \n",
    "elif 'local' in which_pc:\n",
    "    cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import Morris\n",
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.extended_FAST import eFAST\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "import brightway2 as bw\n",
    "import numpy as np\n",
    "from gsa_framework.plotting import histogram_Y1_Y2\n",
    "from gsa_framework.utils import read_hdf5_array\n",
    "\n",
    "\n",
    "def compute_per_worker_delta(num_params):\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "    # 1. Models\n",
    "    # num_influential = num_params // 100\n",
    "    num_influential = 100\n",
    "    iterations_validation = 2000\n",
    "    if num_influential == num_params // 100:\n",
    "        write_dir = path_base / \"morris_model_{}_1percent\".format(num_params)\n",
    "    elif num_influential == 100:\n",
    "        write_dir = path_base / \"morris_model_{}_100\".format(num_params)\n",
    "    model = Morris(num_params=num_params, num_influential=num_influential)\n",
    "    gsa_seed = 3407\n",
    "    validation_seed = 7043\n",
    "\n",
    "    fig_format = [\"html\", \"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "    num_params_correlation_plot = 10\n",
    "    parameter_inds = list(range(num_params_correlation_plot)) + list(\n",
    "        range(num_influential, num_influential + num_params_correlation_plot)\n",
    "    )\n",
    "    iterations = 30000 #2 * num_params\n",
    "    num_resamples = 1\n",
    "    \n",
    "    gsa = DeltaMoment(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        num_resamples=num_resamples,\n",
    "        seed=gsa_seed,\n",
    "    )\n",
    "#     S_dict = gsa.perform_gsa()\n",
    "#     delta = S_dict[\"delta\"]\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=25,\n",
    "    )\n",
    "    conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_worker_delta_lca():\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    iterations = 20000\n",
    "    num_resamples = 1\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"Food\" in act['name']][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "    # Define some variables\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    \n",
    "    fig_format = [\"html\", \"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "    num_params_correlation_plot = 10\n",
    "    parameter_inds = [0,1,2]\n",
    "    \n",
    "    # Setup GSA\n",
    "    gsa = DeltaMoment(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        num_resamples=num_resamples,\n",
    "        seed=gsa_seed,\n",
    "    )\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=25,\n",
    "    )\n",
    "    conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_worker_xgboost_lca():\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"Food\" in act[\"name\"]][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "\n",
    "    parameter_inds_convergence_plot = [1,2,3]  # TODO choose for convergence\n",
    "\n",
    "    num_boost_round = 400\n",
    "    tuning_parameters = {\n",
    "         'max_depth': 6,  \n",
    "         'eta': 0.1,\n",
    "         'objective': 'reg:squarederror',\n",
    "         'n_jobs': -1,\n",
    "         'refresh_leaf': True,\n",
    "         'subsample': 0.6,\n",
    "         'min_child_weight': 0.5,\n",
    "    }\n",
    "    iterations = 2 * num_params\n",
    "    gsa = GradientBoosting(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        seed=gsa_seed,\n",
    "        tuning_parameters=tuning_parameters,\n",
    "        num_boost_round=num_boost_round,\n",
    "        xgb_model=None,\n",
    "    )\n",
    "    S_dict, r2, ev = gsa.perform_gsa(flag_save_S_dict=True, return_stats=True)\n",
    "    try:\n",
    "        print(r2, ev)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=25,\n",
    "    )\n",
    "    conv.run_convergence(\n",
    "        parameter_inds=parameter_inds_convergence_plot,\n",
    "        fig_format=fig_format,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_per_worker_xgboost_lca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_per_worker_delta = dask.delayed(compute_per_worker_delta)\n",
    "model_evals = []\n",
    "# for num_params in [10000]:\n",
    "#     model_eval = task_per_worker_delta(num_params)\n",
    "#     model_evals.append(model_eval)\n",
    "\n",
    "# task_per_worker_delta_lca = dask.delayed(compute_per_worker_delta_lca)\n",
    "# model_eval = task_per_worker_delta_lca()\n",
    "# model_evals.append(model_eval)\n",
    "\n",
    "task_per_worker_xgboost_lca = dask.delayed(compute_per_worker_xgboost_lca)\n",
    "model_eval = task_per_worker_xgboost_lca()\n",
    "model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "path_base = Path(\"/data/user/kim_a/oases_gsa/LSA_scores/LSA_scores_96180_96709.pickle\")\n",
    "with open(path_base, 'rb') as f:\n",
    "    a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[96252]['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import Morris4\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.methods.delta_moment import DeltaMoment\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "\n",
    "    # 1. Models\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 2000\n",
    "    write_dir = path_base / \"{}_morris4\".format(num_params)\n",
    "    model = Morris4(num_params=num_params, num_influential=num_influential)\n",
    "    gsa_seed = 3407\n",
    "    validation_seed = 7043\n",
    "    num_influential_validation = 2*num_influential\n",
    "\n",
    "    fig_format = [\"pickle\"]  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "    # TODO Choose which GSA to perform\n",
    "    flag_sobol = 1\n",
    "    flag_correlation = 0\n",
    "    flag_xgboost = 0\n",
    "    flag_delta = 0\n",
    "\n",
    "    if flag_sobol:\n",
    "        iterations = 100 * num_params\n",
    "        gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "        # S_dict = gsa.generate_gsa_indices()\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "        gsa.plot_sa_results(\n",
    "            S_dict,\n",
    "            S_dict_analytical=model.S_dict_analytical,\n",
    "            fig_format=fig_format,\n",
    "        )\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"TotalIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(total, num_influential_validation, tag=tag)\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "#         val.plot_histogram_Y_all_Y_inf(\n",
    "#             influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "#         )\n",
    "        \n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n",
    "\n",
    "    if flag_correlation:\n",
    "        iterations = 4 * num_params\n",
    "        gsa = CorrelationCoefficients(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        pearson = S_dict[\"pearson\"]\n",
    "        spearman = S_dict[\"spearman\"]\n",
    "#         gsa.plot_sa_results(S_dict, S_boolean=model.S_boolean, fig_format=fig_format)\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"SpearmanIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(\n",
    "            spearman, num_influential_validation, tag=tag\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(\n",
    "#             parameter_inds=parameter_inds,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "    if flag_delta:\n",
    "        iterations = 8 * num_params\n",
    "        num_resamples = 1\n",
    "        gsa = DeltaMoment(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            num_resamples=num_resamples,\n",
    "            seed=gsa_seed,\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        S_dict.pop('delta_conf')\n",
    "        delta = S_dict['delta']\n",
    "        gsa.plot_sa_results(\n",
    "            S_dict,\n",
    "            S_boolean=model.S_boolean,\n",
    "            fig_format=fig_format,\n",
    "        )\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"DeltaIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(\n",
    "            delta, num_influential_validation, tag=tag\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    if flag_xgboost:\n",
    "        if num_params == 1000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.35,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 5000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        elif num_params == 10000:\n",
    "            num_boost_round = 300\n",
    "            tuning_parameters = {\n",
    "                \"max_depth\": 2,  # higher than 10 is definitely not good\n",
    "                \"eta\": 0.25,\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_jobs\": -1,\n",
    "                \"refresh_leaf\": True,\n",
    "                \"subsample\": 0.65,\n",
    "                \"min_child_weight\": 0.5,\n",
    "            }\n",
    "        iterations = 10000\n",
    "        gsa = GradientBoosting(\n",
    "            iterations=iterations,\n",
    "            model=model,\n",
    "            write_dir=write_dir,\n",
    "            seed=gsa_seed,\n",
    "            tuning_parameters=tuning_parameters,\n",
    "            num_boost_round=num_boost_round,\n",
    "            xgb_model=None,\n",
    "        )\n",
    "        S_dict, r2, ev = gsa.perform_gsa(flag_save_S_dict=True, return_stats=True)\n",
    "        print(r2, ev)\n",
    "        # fscores = S_dict[\"fscores\"]\n",
    "        # gsa.plot_sa_results(\n",
    "        #     S_dict,\n",
    "        #     S_boolean=model.S_boolean,\n",
    "        #     fig_format=fig_format,\n",
    "        # )\n",
    "        #\n",
    "        # t0 = time.time()\n",
    "        # val = Validation(\n",
    "        #     model=model,\n",
    "        #     iterations=iterations_validation,\n",
    "        #     seed=validation_seed,\n",
    "        #     default_x_rescaled=None,\n",
    "        #     write_dir=write_dir,\n",
    "        # )\n",
    "        # tag = \"FscoresIndex\"\n",
    "        # influential_Y = val.get_influential_Y_from_gsa(\n",
    "        #     fscores, num_influential_validation, tag=tag\n",
    "        # )\n",
    "        # t1 = time.time()\n",
    "        # print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        # val.plot_histogram_Y_all_Y_inf(\n",
    "        #     influential_Y, num_influential_validation, tag=tag, fig_format=fig_format\n",
    "        # )\n",
    "\n",
    "        # conv = Convergence(\n",
    "        #     gsa.filepath_Y,\n",
    "        #     gsa.num_params,\n",
    "        #     gsa.generate_gsa_indices,\n",
    "        #     gsa.gsa_label,\n",
    "        #     write_dir,\n",
    "        #     num_steps=100,\n",
    "        # )\n",
    "        # conv.run_convergence(\n",
    "        #     parameter_inds=parameter_inds,\n",
    "        #     fig_format=fig_format,\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
