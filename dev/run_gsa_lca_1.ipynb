{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LSA: Remove inputs that result in low output variance, only use 10k inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.validation import Validation\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_hdf5_array, write_pickle\n",
    "import h5py\n",
    "import pickle\n",
    "from setups_paper_gwp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO choose\n",
    "option = 'paper'\n",
    "if option == 'paper':\n",
    "    setup_lca_model = setup_lca_model_paper\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa')\n",
    "    write_dir = path_base / \"lca_model_food_10000\"\n",
    "elif option == 'setac':\n",
    "    setup_lca_model = setup_lca_model_oases\n",
    "    path_base = Path('/data/user/kim_a/')\n",
    "    write_dir = path_base / 'oases_gsa_gwp_10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    num_params_gsa = 10000\n",
    "    \n",
    "    model, write_dir, gsa_seed = setup_lca_model(\n",
    "        num_params=None, \n",
    "        write_dir=write_dir, \n",
    "        flag_generate_scores_dict=True,\n",
    "    )\n",
    "\n",
    "    # Define some variables\n",
    "    iterations_validation = 2000\n",
    "    validation_seed = 66666\n",
    "    fig_format = [\"pickle\"]\n",
    "\n",
    "    # Make sure  that the chosen num_params in LCA are appropriate\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=model.default_uncertain_amounts,\n",
    "        write_dir=write_dir,\n",
    "    )\n",
    "    \n",
    "    tag = \"LocalSA\"\n",
    "    scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "    uncertain_tech_params_where_subset, _ = model.get_nonzero_params_from_num_params(scores_dict, num_params_gsa)\n",
    "    parameter_choice = []\n",
    "    for u in uncertain_tech_params_where_subset:\n",
    "        where_temp = np.where(model.uncertain_tech_params_where == u)[0]\n",
    "        assert len(where_temp) == 1\n",
    "        parameter_choice.append(where_temp[0])\n",
    "    parameter_choice.sort()\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(parameter_choice=parameter_choice, tag=tag)\n",
    "    fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=num_params_gsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run all GSA for lca model with 10k inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_pc = \"merlin_paper_gsa\"\n",
    "if 'merlin' in which_pc:\n",
    "    path_dask_logs = Path('/data/user/kim_a/dask_logs')\n",
    "    path_dask_logs.mkdir(parents=True, exist_ok=True)\n",
    "    cluster = SLURMCluster(cores     = 8, \n",
    "                           memory    ='30GB', \n",
    "                           walltime  = '20:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = path_dask_logs.as_posix(),\n",
    "                           log_directory   = path_dask_logs.as_posix(),\n",
    "                           queue=\"daily\",\n",
    "                           ) \n",
    "elif 'local' in which_pc:\n",
    "    cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validate GSA results TODO wrt all 180k inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/')\n",
    "# LCA model\n",
    "bw.projects.set_current(\"GSA for oases\")\n",
    "co = bw.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"average consumption\" in act['name']][0]\n",
    "print(demand_act)\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\")\n",
    "\n",
    "# Define some variables\n",
    "num_params = 172051\n",
    "iterations_validation = 2000\n",
    "write_dir = path_base / \"oases_gsa\"\n",
    "model = LCAModel(demand, method, write_dir) # TODO add num_params later\n",
    "validation_seed = 66666\n",
    "fig_format = [\"html\", \"pickle\"]\n",
    "\n",
    "t0 = time.time()\n",
    "# Make sure  that the chosen num_params in LCA are appropriate\n",
    "val = Validation(\n",
    "    model=model,\n",
    "    iterations=iterations_validation,\n",
    "    seed=validation_seed,\n",
    "    default_x_rescaled=model.default_uncertain_amounts,\n",
    "    write_dir=write_dir,\n",
    ")\n",
    "\n",
    "spearman = S_dict[\"spearman\"]\n",
    "num_influential = 60\n",
    "tag = \"SpearmanIndex\"\n",
    "\n",
    "parameter_choice_inf = np.argsort(abs(spearman))[::-1][:num_influential]\n",
    "parameter_choice_inf.sort()\n",
    "params_where_inf = gsa_corr.model.uncertain_tech_params_where[parameter_choice_inf]\n",
    "params_where_all = model.uncertain_tech_params_where\n",
    "\n",
    "parameter_choice = np.zeros(num_influential,dtype=int)\n",
    "parameter_choice[:] = np.nan\n",
    "for i,p in enumerate(params_where_inf):\n",
    "    parameter_choice[i] = np.where(params_where_all==p)[0]\n",
    "\n",
    "influential_Y = val.get_influential_Y_from_parameter_choice(parameter_choice=parameter_choice, tag=tag)\n",
    "t1 = time.time()\n",
    "print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "fig_format = ['html', 'pickle']\n",
    "# val.plot_histogram_Y_all_Y_inf(\n",
    "#     influential_Y, num_influential, tag=tag, fig_format=fig_format, bin_min=None, bin_max=None, num_bins=60\n",
    "# )\n",
    "# val.plot_correlation_Y_all_Y_inf(\n",
    "#     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.plotting import *\n",
    "lcia_scores_text = \"LCIA scores, [kg CO2-eq]\"\n",
    "diff = 0\n",
    "diff = 1869.6814802713172-1150.4295714576062\n",
    "bin_min = 1800\n",
    "bin_max = 2150\n",
    "num_bins = 60\n",
    "fig = histogram_Y1_Y2(\n",
    "    val.Y_all+diff,\n",
    "    influential_Y+diff,\n",
    "    default_Y=None,\n",
    "    bin_min=bin_min,\n",
    "    bin_max=bin_max,\n",
    "    num_bins=num_bins,\n",
    "    trace_name1=\"All parameters vary\",\n",
    "    trace_name2=\"Only influential vary\",\n",
    "    color1=\"#636EFA\",\n",
    "    color2=\"#EF553B\",\n",
    "    color_default_Y=\"red\",\n",
    "    opacity=0.65,\n",
    "    xaxes_title_text=lcia_scores_text,\n",
    ")\n",
    "fig.update_yaxes(range=[-10,140])\n",
    "fig.show()\n",
    "write_pickle(fig, \"validation_60inf_histogram_spearman.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = correlation_Y1_Y2(\n",
    "    Y1=val.Y_all+diff,\n",
    "    Y2=influential_Y+diff,\n",
    "    start=0,\n",
    "    end=80,\n",
    "    trace_name1=\"All parameters vary\",\n",
    "    trace_name2=\"Only influential vary\",\n",
    "    yaxes1_title_text=lcia_scores_text,\n",
    "    xaxes2_title_text=lcia_scores_text,\n",
    "    yaxes2_title_text=lcia_scores_text,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[bin_min, bin_max],\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    range=[bin_min, bin_max],\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig.show()\n",
    "write_pickle(fig, \"validation_60inf_correlation_spearman.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Print exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.validation import Validation\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_hdf5_array, write_pickle\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 35000\n",
    "iterations = 2*num_params\n",
    "gsa_corr = setup_corr(num_params, iterations)\n",
    "S_dict = gsa_corr.generate_gsa_indices()\n",
    "spearman = S_dict[\"spearman\"]\n",
    "\n",
    "num_influential = 20\n",
    "imp_inds = np.argsort(spearman)[::-1][:num_influential]\n",
    "imp_tech = gsa_corr.model.uncertain_tech_params[imp_inds]\n",
    "spearman_inf = spearman[imp_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "row_acts, col_acts = [],[]\n",
    "for p in imp_tech[:num_influential]:\n",
    "    row = p['row']\n",
    "    col = p['col']\n",
    "    row_acts.append(bw.get_activity(gsa_corr.model.lca.reverse_dict()[0][row]))\n",
    "    col_acts.append(bw.get_activity(gsa_corr.model.lca.reverse_dict()[0][col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for i in range(num_influential):\n",
    "    input_act  = row_acts[i].as_dict()\n",
    "    output_act = col_acts[i].as_dict()\n",
    "    dict_ = {\n",
    "        \"input activity\": input_act['name'],\n",
    "        \"input location\": input_act['location'],\n",
    "        \"input reference product\": input_act['reference product'],\n",
    "        \"input unit\": input_act['unit'],\n",
    "        \"output activity\": output_act['name'],\n",
    "        \"output location\": output_act['location'],\n",
    "        \"output reference product\": output_act['reference product'],\n",
    "        \"output unit\": output_act['unit'],\n",
    "        \"exchange amount\": imp_tech[i]['amount'],\n",
    "        \"exchange scale\": imp_tech[i]['scale'],\n",
    "        \"exchange loc\": imp_tech[i]['loc'],\n",
    "        \"exchange Spearman rank coef.\": spearman_inf[i],\n",
    "    }\n",
    "    list_.append(dict_)\n",
    "df = pd.DataFrame(list_)\n",
    "df.to_excel('influential_exchanges.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = gsa_corr.write_dir / \"arrays\" / 'row_acts.pickle'\n",
    "# with open(filename, 'wb') as f:\n",
    "#      pickle.dump(row_acts, f)\n",
    "    \n",
    "# filename = gsa_corr.write_dir / \"arrays\" / 'col_acts.pickle'\n",
    "# with open(filename, 'wb') as f:\n",
    "#      pickle.dump(col_acts, f)\n",
    "        \n",
    "# filename = gsa_corr.write_dir / \"arrays\" /  'imp_tech.pickle'\n",
    "# with open(filename, 'wb') as f:\n",
    "#      pickle.dump(imp_tech, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = gsa_corr.write_dir / \"arrays\" /  'row_acts.pickle'\n",
    "# with open(filename, 'rb') as f:\n",
    "#     row_acts = pickle.load(f)\n",
    "    \n",
    "# filename = gsa_corr.write_dir / \"arrays\" /  'col_acts.pickle'\n",
    "# with open(filename, 'rb') as f:\n",
    "#     col_acts = pickle.load(f)\n",
    "\n",
    "# filename = gsa_corr.write_dir / \"arrays\" / 'imp_tech.pickle'\n",
    "# with open(filename, 'rb') as f:\n",
    "#     imp_tech = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_plot = imp_tech['scale']\n",
    "# amounts_plot = imp_tech['amount']\n",
    "\n",
    "# xscale_inf = 100\n",
    "# xscale_max = np.round((max(spearman)//0.2 + 1)*0.2, 1)*xscale_inf\n",
    "# xtickvals_inf = np.arange(0,-xscale_max-1,-20)\n",
    "# xticktext_inf = -xtickvals_inf/xscale_inf\n",
    "\n",
    "# xscale_scale = int(np.ceil(max(scale_plot) * xscale_inf / 20) * 20)\n",
    "# xtickvals_scale = np.arange(0,-xscale_scale-1,-20)\n",
    "# xticktext_scale = -xtickvals_scale/100\n",
    "\n",
    "xscale_inf = 200\n",
    "xtickvals_inf = np.array([-0.0,-0.2,-0.4,-0.6,-0.8,-1.0])*100\n",
    "xticktext_inf = -xtickvals_inf / xscale_inf\n",
    "\n",
    "xscale_scale = 100\n",
    "xtickvals_scale = np.array([0, -25,  -50,  -75,  -100, -125,])#np.arange(0,-xscale_scale-1,-20)\n",
    "xticktext_scale = np.array([0, 0.25,  0.5, 0.75,  1.0, 1.25,])\n",
    "\n",
    "n_features_plot = num_influential\n",
    "importance_plot = spearman[imp_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "#     'scale': '#fc6955',\n",
    "    'scale': 'gray',\n",
    "    'agribalyse': '#00e779',\n",
    "    'inf': '#2f91e5',\n",
    "    'mobility': '#9467bd',\n",
    "    'electricity': '#109618',\n",
    "    'agriculture': '#ffa15a',\n",
    "#     'computing': '#0099c6',   \n",
    "    'computing': '#4c78a8',\n",
    "    'combustion': '#b82e2e',   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dict = {\n",
    "    # Locations\n",
    "    \"Europe without Switzerland\": \"EU without CH\",\n",
    "    # Row acts\n",
    "    \"petrol production, unleaded, petroleum refinery operation\": \"petrol production, unleaded, refinery operation\",\n",
    "    \"market for printed wiring board, surface mounted, unspecified, Pb free\": \"market for printed wiring board, Pb free\",\n",
    "    \"market for wafer, fabricated, for integrated circuit\": \"market for wafer, for integrated circuit\",\n",
    "    # Col acts\n",
    "    \"electricity voltage transformation from high to medium voltage\": \"el. voltage transformation, high to medium\",\n",
    "    \"electricity voltage transformation from medium to low voltage\": \"el. voltage transformation, medium to low\",\n",
    "    \"printed wiring board production, surface mounted, unspecified, Pb free\": \"printed wiring board production, Pb free\",\n",
    "    \"heat production, natural gas, at boiler condensing modulating <100kW\": \"heat production, natural gas, at boiler <100kW\",\n",
    "    \"printed wiring board production, surface mounted, unspecified, Pb containing\": \"printed wiring board production, Pb containing\",\n",
    "    \"heat production, light fuel oil, at boiler 10kW condensing, non-modulating\": \"heat production, light fuel oil, boiler 10kW condensing\",\n",
    "    \"heat production, light fuel oil, at boiler 10kW, non-modulating\": \"heat production, light fuel oil, at boiler 10kW\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_acts_plot, col_acts_plot = [], []\n",
    "for i in range(num_influential):\n",
    "    row_name = row_acts[i]['name']\n",
    "    row_location = row_acts[i]['location']\n",
    "    dict_row = {\n",
    "        'name': titles_dict.get(row_name, row_name),\n",
    "        'location': titles_dict.get(row_location, row_location)\n",
    "    }\n",
    "    row_acts_plot.append(dict_row)\n",
    "    \n",
    "    col_name = col_acts[i]['name']\n",
    "    col_location = col_acts[i]['location']\n",
    "    dict_col = {\n",
    "        'name': titles_dict.get(col_name, col_name),\n",
    "        'location': titles_dict.get(col_location, col_location)\n",
    "    }\n",
    "    col_acts_plot.append(dict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for i in range(n_features_plot):\n",
    "    # Set color depending in database\n",
    "    col_color = 'black'\n",
    "    row_color = 'black'\n",
    "    if 'voltage' in col_acts_plot[i]['name']:\n",
    "        col_color = colors['electricity']\n",
    "        row_color = colors['electricity']\n",
    "    elif 'soybean' in col_acts_plot[i]['name'] or 'cheese' in col_acts_plot[i]['name']:\n",
    "        col_color = colors['agriculture']\n",
    "        row_color = colors['agriculture']\n",
    "    elif 'car' in col_acts_plot[i]['name'] or 'steel' in col_acts_plot[i]['name'] or 'diesel' in col_acts_plot[i]['name']:\n",
    "        col_color = colors['mobility']\n",
    "        row_color = colors['mobility']\n",
    "    elif 'circuit' in col_acts_plot[i]['name'] or 'wiring' in col_acts_plot[i]['name'] \\\n",
    "    or 'computer' in col_acts_plot[i]['name'] or 'display' in col_acts_plot[i]['name']:\n",
    "        col_color = colors['computing']\n",
    "        row_color = colors['computing']\n",
    "    elif 'heat' in col_acts_plot[i]['name'] or 'petrol' in col_acts_plot[i]['name'] or 'well' in col_acts_plot[i]['name']:\n",
    "        col_color = colors['combustion']\n",
    "        row_color = colors['combustion']\n",
    "   \n",
    "    ann_input = dict(\n",
    "        x=12,\n",
    "        y=i-0.15,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text=\"Output -> \" \\\n",
    "               + col_acts_plot[i]['name'] + ', ' \\\n",
    "               + col_acts_plot[i]['location'],\n",
    "        xanchor = 'left',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,\n",
    "        font_size=7,\n",
    "        font_color=col_color\n",
    "        )\n",
    "    ann_output = dict(\n",
    "        x=12,\n",
    "        y=i+0.15,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text=\"Input   -> \" \\\n",
    "                + row_acts_plot[i]['name'] + ', ' \\\n",
    "                + row_acts_plot[i]['location'],\n",
    "        xanchor = 'left',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,\n",
    "        font_size=7,\n",
    "        font_color=row_color\n",
    "        )\n",
    "    ann_text = dict(\n",
    "        x=0,\n",
    "        y=i,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text=i+1,\n",
    "        xanchor = 'left',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,\n",
    "        \n",
    "        )\n",
    "    annotations.append(ann_input)\n",
    "    annotations.append(ann_output)\n",
    "    annotations.append(ann_text)\n",
    "\n",
    "# Add ticks and annotations to feature importance\n",
    "for j in range(xtickvals_inf.shape[0]):\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=xtickvals_inf[j],\n",
    "            y=-1,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            text=xticktext_inf[j],\n",
    "            xanchor = 'center',\n",
    "            yanchor = 'middle',\n",
    "            showarrow = False,\n",
    "            font_color=colors['inf']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "annotations.append(\n",
    "    dict(\n",
    "        x=-xscale_scale/2,\n",
    "        y=-1.5,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text='Feature importance',\n",
    "        xanchor = 'center',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,\n",
    "        font_color=colors['inf']\n",
    "    )\n",
    ")\n",
    " \n",
    "# Add ticks and annotations to scale values\n",
    "for j in range(xtickvals_scale.shape[0]):\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=xtickvals_scale[j],\n",
    "            y=-2.2,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            text=xticktext_scale[j],\n",
    "            xanchor = 'center',\n",
    "            yanchor = 'middle',\n",
    "            showarrow = False,\n",
    "            font_color=colors['scale'],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "annotations.append(\n",
    "    dict(\n",
    "        x=-xscale_scale/2,\n",
    "        y=-2.7,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text='Scale (lognormal distr)',\n",
    "        xanchor = 'center',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,\n",
    "        font_color=colors['scale']\n",
    "    )\n",
    ")\n",
    "    \n",
    "annotations.append(\n",
    "    dict(\n",
    "        x=11,\n",
    "        y=-1.5,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        text='Ecoinvent technosphere exchanges',\n",
    "        xanchor = 'left',\n",
    "        yanchor = 'middle',\n",
    "        showarrow = False,)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = []\n",
    "# for i in range(n_features_plot):\n",
    "#     # Set color depending in database\n",
    "#     col_color = 'black'\n",
    "#     if col_acts[i]['database'] != 'ecoinvent 3.6 cutoff':\n",
    "#         col_color = colors['agribalyse']\n",
    "#     row_color = 'black'\n",
    "#     if row_acts[i]['database'] != 'ecoinvent 3.6 cutoff':\n",
    "#         row_color = colors['agribalyse']\n",
    "        \n",
    "#     ann_input = dict(\n",
    "#         x=12,\n",
    "#         y=i-0.15,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text=\"Output \" + col_acts[i]['database'][:10] + ' -> ' \\\n",
    "#                        + col_acts[i]['name'] + ', ' \\\n",
    "#                        + col_acts[i]['location'],\n",
    "#         xanchor = 'left',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,\n",
    "#         font_size=7,\n",
    "#         font_color=col_color\n",
    "#         )\n",
    "#     ann_output = dict(\n",
    "#         x=12,\n",
    "#         y=i+0.15,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text=\"Input   \" + row_acts[i]['database'][:10] + ' -> ' \\\n",
    "#                         + row_acts[i]['name'] + ', ' \\\n",
    "#                         + row_acts[i]['location'],\n",
    "#         xanchor = 'left',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,\n",
    "#         font_size=7,\n",
    "#         font_color=row_color\n",
    "#         )\n",
    "#     ann_text = dict(\n",
    "#         x=0,\n",
    "#         y=i,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text=i+1,\n",
    "#         xanchor = 'left',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,\n",
    "        \n",
    "#         )\n",
    "#     annotations.append(ann_input)\n",
    "#     annotations.append(ann_output)\n",
    "#     annotations.append(ann_text)\n",
    "\n",
    "# # Add ticks and annotations to feature importance\n",
    "# for j in range(xtickvals_inf.shape[0]):\n",
    "#     annotations.append(\n",
    "#         dict(\n",
    "#             x=xtickvals_inf[j],\n",
    "#             y=-1,\n",
    "#             xref=\"x\",\n",
    "#             yref=\"y\",\n",
    "#             text=xticktext_inf[j],\n",
    "#             xanchor = 'center',\n",
    "#             yanchor = 'middle',\n",
    "#             showarrow = False,\n",
    "#             font_color=colors['inf']\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# annotations.append(\n",
    "#     dict(\n",
    "#         x=-xscale_scale/2,\n",
    "#         y=-1.5,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text='Feature importance',\n",
    "#         xanchor = 'center',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,\n",
    "#         font_color=colors['inf']\n",
    "#     )\n",
    "# )\n",
    " \n",
    "# # Add ticks and annotations to scale values\n",
    "# for j in range(xtickvals_scale.shape[0]):\n",
    "#     annotations.append(\n",
    "#         dict(\n",
    "#             x=xtickvals_scale[j],\n",
    "#             y=-2.2,\n",
    "#             xref=\"x\",\n",
    "#             yref=\"y\",\n",
    "#             text=xticktext_scale[j],\n",
    "#             xanchor = 'center',\n",
    "#             yanchor = 'middle',\n",
    "#             showarrow = False,\n",
    "#             font_color=colors['scale'],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# annotations.append(\n",
    "#     dict(\n",
    "#         x=-xscale_scale/2,\n",
    "#         y=-2.7,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text='Scale (lognormal distr)',\n",
    "#         xanchor = 'center',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,\n",
    "#         font_color=colors['scale']\n",
    "#     )\n",
    "# )\n",
    "    \n",
    "# annotations.append(\n",
    "#     dict(\n",
    "#         x=11,\n",
    "#         y=-1.5,\n",
    "#         xref=\"x\",\n",
    "#         yref=\"y\",\n",
    "#         text='Corresponding exchanges',\n",
    "#         xanchor = 'left',\n",
    "#         yanchor = 'middle',\n",
    "#         showarrow = False,)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "opacity_ = 0.8\n",
    "\n",
    "# Importance\n",
    "fig.add_trace( go.Bar( x=importance_plot*(-xscale_inf),\n",
    "                       y=np.arange(n_features_plot),\n",
    "                       name='All features',\n",
    "                       opacity=opacity_,\n",
    "                       orientation='h',\n",
    "                       width=[0.3]*n_features_plot,\n",
    "                       showlegend=False,\n",
    "                      marker_color=colors['inf']\n",
    "                     ),              \n",
    "             )\n",
    "\n",
    "# Lognormal scales\n",
    "fig.add_trace( go.Bar( x=scale_plot*(-xscale_scale),\n",
    "                       y=np.arange(n_features_plot),\n",
    "                       name='All features',\n",
    "                       opacity=opacity_,\n",
    "                       orientation='h',\n",
    "                       width=[0.3]*n_features_plot,\n",
    "                       showlegend=False,\n",
    "                       marker_color=colors['scale']\n",
    "                     ),\n",
    "             )\n",
    "\n",
    "fig.add_trace( go.Scatter( x=[-130,170],\n",
    "                           y=[-0.6,-0.6],\n",
    "                           mode='lines',\n",
    "                           showlegend=False,\n",
    "                           line_color='white'\n",
    "                     ),\n",
    "             )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = xtickvals_inf,\n",
    "        ticktext = xticktext_inf,\n",
    "        showticklabels = False,\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = np.arange(n_features_plot),\n",
    "        ticktext = [],\n",
    "        autorange = 'reversed',\n",
    "        showticklabels = False,\n",
    "    ),\n",
    "    width=500,\n",
    "    height=num_influential*24,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    annotations = annotations,\n",
    "    barmode='group',\n",
    "    bargap = 0.4,\n",
    "    yaxis_showgrid=False,\n",
    "    yaxis_zeroline=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = gsa_corr.write_dir / \"figures\" /  'fig_gsa_results.pickle'\n",
    "with open(filename, 'wb') as f:\n",
    "     pickle.dump(fig, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "project = 'GSA for oases'\n",
    "bw.projects.set_current(project)\n",
    "co = bw.Database(\"CH consumption 1.0\")\n",
    "demand_act = co.search('ch hh average consumption')\n",
    "assert len(demand_act) == 1\n",
    "demand = {demand_act[0]: 1}\n",
    "list_methods = [('IPCC 2013', 'climate change', 'GWP 100a')]\n",
    "sectors = [act for act in co if 'sector' in act[\"name\"]]\n",
    "list_fus = []\n",
    "for act in sectors:\n",
    "    list_fus.append({act: 1})\n",
    "    \n",
    "bw.calculation_setups['sector_contribution_analysis'] = {'inv':list_fus, 'ia':list_methods}\n",
    "myMultiLCA = bw.MultiLCA('sector_contribution_analysis')\n",
    "lcia_unit = bw.Method(list_methods[0]).metadata['unit']\n",
    "fus = [bw.get_activity(list(el.keys())[0])['name'][:] for el in list_fus]\n",
    "df = pd.DataFrame(index=fus, columns=[lcia_unit], data=myMultiLCA.results)\n",
    "df['units'] = [bw.get_activity(list(el.keys())[0])['unit'] for el in list_fus]\n",
    "df.sort_values(lcia_unit, ascending=False, inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.iloc[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_plot.plot.barh()\n",
    "ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_hdf5_array, write_pickle\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_params = 10000\n",
    "    model, write_dir, gsa_seed = setup_lca_model(num_params)\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "    \n",
    "    iterations = 2 * num_params\n",
    "    gsa = CorrelationCoefficients(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        seed=gsa_seed,\n",
    "    )\n",
    "    S_dict = gsa.generate_gsa_indices()\n",
    "    spearman = S_dict[\"spearman\"]\n",
    "    \n",
    "    num_convergence_steps = 100\n",
    "    num_convergence_plot = 10\n",
    "    parameter_inds_convergence_plot = np.hstack(\n",
    "        [\n",
    "            np.argsort(spearman)[::-1][:num_convergence_plot],\n",
    "            np.argsort(spearman)[::-1][-num_convergence_plot:],\n",
    "        ]\n",
    "    )\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        write_dir,\n",
    "        num_steps=num_convergence_steps,\n",
    "    )\n",
    "    conv.run_convergence(\n",
    "        parameter_inds=parameter_inds_convergence_plot,\n",
    "        fig_format=fig_format,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
