{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobol indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from gsa_framework.sensitivity_methods.saltelli_sobol import sobol_indices_stability\n",
    "from gsa_framework.convergence_robustness_validation.convergence import Convergence\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_pickle\n",
    "from setups_paper_gwp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "\n",
    "    # Sobol stability dictionaries\n",
    "    num_params = 10000\n",
    "    iterations = 100 * num_params\n",
    "    num_steps = 50\n",
    "    num_bootstrap = 120\n",
    "\n",
    "    gsa = setup_salt(num_params, iterations, setup_morris4_model, path_base)\n",
    "\n",
    "    # Convergence class\n",
    "    conv = Convergence(\n",
    "        gsa.filepath_Y,\n",
    "        gsa.num_params,\n",
    "        gsa.generate_gsa_indices,\n",
    "        gsa.gsa_label,\n",
    "        gsa.write_dir,\n",
    "        num_steps=num_steps,\n",
    "    )\n",
    "    np.random.seed(gsa.seed)\n",
    "    stability_seeds = np.random.randint(\n",
    "        low=0,\n",
    "        high=2147483647,\n",
    "        size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    "    )\n",
    "\n",
    "    filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "        gsa.gsa_label,\n",
    "        gsa.sampling_label,\n",
    "        gsa.iterations,\n",
    "        conv.iterations_step,\n",
    "        num_bootstrap,\n",
    "        gsa.seed,\n",
    "    )\n",
    "    filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "    if filepath_S.exists():\n",
    "        print(\"--> {} already exists\".format(filename_S))\n",
    "        S_dict_stability = read_pickle(filepath_S)\n",
    "    else:\n",
    "        Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "        S_dict_stability = sobol_indices_stability(\n",
    "            Y,\n",
    "            num_params,\n",
    "            conv.iterations_for_convergence,\n",
    "            num_bootstrap,\n",
    "            stability_seeds,\n",
    "        )\n",
    "        write_pickle(S_dict_stability, filepath_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble multiple stability_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Morris4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stability_dict_from_seeds(seeds, model_dir_array, filenames_stability_dict):\n",
    "    stability_dict_all = {}\n",
    "    for gsa_method, path in filenames_stability_dict.items():\n",
    "        stability_dict_raw = {}\n",
    "        steps_temp = {}\n",
    "        for seed in seeds:\n",
    "            filepath = model_dir_array / path.replace('seed', str(seed))\n",
    "            data = read_pickle(filepath)\n",
    "            steps_temp[seed] = list(data.keys())\n",
    "            stability_dict_raw[seed] = data\n",
    "        steps = np.array(list(steps_temp.values()))\n",
    "        assert (steps == steps[0]).all() # make sure that steps are the same\n",
    "        steps = steps[0]\n",
    "        # Init stability_dict\n",
    "        stability_dict = {}\n",
    "        for step in steps:\n",
    "            for seed in seeds:\n",
    "                stability_dict[step] = {}\n",
    "                for stat_name,data in stability_dict_raw[seed][step].items():\n",
    "                    stability_dict[step][stat_name] = np.zeros([0,data.shape[1]])\n",
    "        # Concatenate data in stability_dict\n",
    "        for step in steps:\n",
    "            for seed in seeds:\n",
    "                for stat_name,data in stability_dict_raw[seed][step].items():\n",
    "                    stability_dict[step][stat_name] = np.vstack(\n",
    "                        [\n",
    "                            stability_dict[step][stat_name],\n",
    "                            stability_dict_raw[seed][step][stat_name],\n",
    "                        ]\n",
    "                    )\n",
    "        stability_dict_all[gsa_method] = stability_dict\n",
    "    return stability_dict_all\n",
    "\n",
    "def get_stability_dict_all_seeds(seeds, model_dir_array, filenames_stability_dict):\n",
    "    # Get data\n",
    "    str_seed = ''\n",
    "    for seed in seeds:\n",
    "        if len(str_seed) == 0:\n",
    "            str_seed = \"{}\".format(seed)\n",
    "        else:\n",
    "            str_seed += \"_{}\".format(seed)\n",
    "\n",
    "    S_dict = {}\n",
    "    for gsa_method, filename in filenames_stability_dict.items():\n",
    "        filename_stability_concatenated = filename.replace('seed', str_seed)\n",
    "        list_ = filename_stability_concatenated.split('.')\n",
    "        list_[-3] = \"{:d}\".format(int(list_[-3])*len(seeds))\n",
    "        filename_stability_concatenated = \".\".join(list_)\n",
    "        print(filename_stability_concatenated)\n",
    "        filepath = model_dir_array / filename_stability_concatenated\n",
    "        if filepath.exists():\n",
    "            S_dict[gsa_method] = read_pickle(filepath)\n",
    "        else:\n",
    "            stability_dict_all = create_stability_dict_from_seeds(seeds, model_dir_array, filenames_stability_dict)\n",
    "            S_dict_gsa = stability_dict_all[gsa_method]\n",
    "            S_dict[gsa_method] = S_dict_gsa\n",
    "            write_pickle(S_dict_gsa, filepath)\n",
    "    return S_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Morris\n",
    "num_params = 10000\n",
    "path_base = Path('/data/user/kim_a/paper_gsa/')\n",
    "model_dir_array = path_base / \"{}_morris4\".format(num_params) / \"arrays\" \n",
    "seeds = [3407, 6000814]\n",
    "filenames_stability_dict_all_models = {\n",
    "    1000: {\n",
    "        'corr': \"stability.S.correlationsGsa.randomSampling.4000Step80.60.seed.pickle\",\n",
    "        'delt': \"stability.S.deltaGsaNr0.latinSampling.8000Step160.60.seed.pickle\",\n",
    "        \"xgbo\": \"stability.S.xgboostGsa_Lr0.1G0Mcw30Md2RegL10RegA0Ne500Ss0.6Cbt0.3_.randomSampling.4000Step80.60.seed.pickle\",  \n",
    "    },\n",
    "    5000: {\n",
    "        'corr': \"stability.S.correlationsGsa.randomSampling.20000Step400.60.seed.pickle\",\n",
    "        'delt': \"stability.S.deltaGsaNr0.latinSampling.40000Step800.60.seed.pickle\",\n",
    "        'xgbo': \"stability.S.xgboostGsa_Lr0.2G0Mcw300Md2RegL0RegA0Ne800Ss0.3Cbt0.3_.randomSampling.20000Step400.60.seed.pickle\",\n",
    "    },\n",
    "    10000: {\n",
    "        'corr': \"stability.S.correlationsGsa.randomSampling.40000Step800.60.seed.pickle\",\n",
    "        'delt': \"stability.S.deltaGsaNr0.latinSampling.80000Step1600.60.seed.pickle\",\n",
    "        'xgbo': \"stability.S.xgboostGsa_Lr0.2G0Mcw600Md2RegL0RegA0Ne1500Ss0.2Cbt0.2_.randomSampling.40000Step800.60.seed.pickle\",\n",
    "    }\n",
    "}\n",
    "\n",
    "S_dict = get_stability_dict_all_seeds(seeds, model_dir_array, filenames_stability_dict_all_models[num_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dict['corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_dir_array / \"stability.S.correlationsGsa.randomSampling.4000Step80.60.3407.pickle\"\n",
    "aa = read_pickle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model_dir_array / \"stability.S.correlationsGsa.randomSampling.4000Step80.60.6000814.pickle\"\n",
    "bb = read_pickle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = 3920\n",
    "ai = aa[itera]['spearman']\n",
    "bi = bb[itera]['spearman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.vstack([ai, bi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "t,y = st.t.interval(0.95, 1, loc=np.mean(c), scale=st.sem(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(t), max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsa-dev]",
   "language": "python",
   "name": "conda-env-gsa-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
