{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import stats_arrays as sa\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from gsa_framework.models.life_cycle_assessment import LCAModelBase\n",
    "from gsa_framework.sensitivity_analysis.correlations import Correlations\n",
    "from gsa_framework.sensitivity_analysis.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.utils import read_pickle, write_pickle, write_hdf5_array\n",
    "from setups_paper_gwp import setup_corr, setup_lca_model_protocol\n",
    "# from gsa_framework.utils import read_hdf5_array, write_hdf5_array\n",
    "# from gsa_framework.visualization.plotting import plot_correlation_Y1_Y2, plot_histogram_Y1_Y2\n",
    "\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a')\n",
    "\n",
    "# LCA model\n",
    "bd.projects.set_current(\"GSA for protocol\")\n",
    "co = bd.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"Food\" in act[\"name\"]]\n",
    "assert len(demand_act) == 1\n",
    "demand_act = demand_act[0]\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "\n",
    "num_params = 20000\n",
    "iter_corr = 4*num_params\n",
    "gsa_corr = setup_corr(num_params, iter_corr, setup_lca_model_protocol, path_base)\n",
    "S = gsa_corr.perform_gsa()\n",
    "spearman = S['spearman']\n",
    "inf_sorted = np.argsort(np.abs(spearman))[::-1]\n",
    "\n",
    "model, write_dir, gsa_seed = setup_lca_model_protocol(\n",
    "    path_base,\n",
    "    num_params=None,\n",
    "    write_dir=None,\n",
    ")\n",
    "\n",
    "path_lsa = model.write_dir / \"LSA_scores\"\n",
    "path_lsa_include_inds_bio = path_lsa / \"include_inds_bio.pickle\"\n",
    "include_inds_bio = read_pickle(path_lsa_include_inds_bio)\n",
    "path_lsa_include_inds_cf = path_lsa / \"include_inds_cf.pickle\"\n",
    "include_inds_cf = read_pickle(path_lsa_include_inds_cf)\n",
    "\n",
    "include_inds_tech_forX = np.arange(model.uncertain_exchange_lengths['tech'])\n",
    "include_inds_bio_forX  = model.uncertain_exchange_lengths['tech'] + include_inds_bio\n",
    "include_inds_cf_forX   = model.uncertain_exchange_lengths['tech'] + \\\n",
    "                         model.uncertain_exchange_lengths['bio']  + include_inds_cf\n",
    "parameter_choice_rm_noninf = np.hstack(\n",
    "    [include_inds_tech_forX, include_inds_bio_forX, include_inds_cf_forX]\n",
    ")\n",
    "\n",
    "scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\", model.uncertain_exchanges_types)\n",
    "num_params_lsa = 20000 #10000\n",
    "where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "# num_params_ranking = 200\n",
    "# gsa_seed_ranking = 555666\n",
    "# iterations_ranking = num_params_ranking * 1600\n",
    "# parameter_choice_inf = parameter_choice_rm_lowinf[inf_sorted[:num_params_ranking]]\n",
    "# parameter_choice_inf = np.sort(parameter_choice_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(parameter_choice_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph traversal screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "\n",
    "from dev.utils_graph_traversal import \\\n",
    "    filter_uncertain_technosphere_exchanges, \\\n",
    "    filter_uncertain_biosphere_exchanges, \\\n",
    "    filter_uncertain_characterization_exchanges, \\\n",
    "    collect_uncertain_exchanges\n",
    "\n",
    "bd.projects.set_current(\"GSA for protocol\")\n",
    "co = bd.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"Food\" in act[\"name\"]]\n",
    "assert len(demand_act) == 1\n",
    "demand_act = demand_act[0]\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "lca = bc.LCA(demand, method)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "\n",
    "def graph_traversal_screening(lca, model, write_dir, cutoff, num_params_ranking):\n",
    "    \n",
    "    cutoff_str = '%.2E' % Decimal(cutoff)\n",
    "    filename = \"cutoff{}.params{}.pickle\".format(cutoff_str, num_params_ranking)\n",
    "    filepath = write_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        data = read_pickle(filepath)\n",
    "    else:\n",
    "        exchanges_dict_filename = \"exchanges_dict.cutoff{}.pickle\".format(cutoff_str)\n",
    "        exchanges_dict_filepath = write_dir / exchanges_dict_filename\n",
    "        if exchanges_dict_filepath.exists():\n",
    "            exchanges_dict = read_pickle(exchanges_dict_filepath)\n",
    "            tech_inds_uncertain = exchanges_dict['tech']\n",
    "            bio_inds_uncertain = exchanges_dict['bio']\n",
    "            cf_inds_uncertain = exchanges_dict['cf']\n",
    "        else:\n",
    "            # tech_inds = filter_technosphere_exchanges(lca, cutoff)\n",
    "            tech_inds_uncertain = filter_uncertain_technosphere_exchanges(lca, cutoff, 1e8)\n",
    "            # bio_inds  = filter_biosphere_exchanges(lca, cutoff)\n",
    "            bio_inds_uncertain = filter_uncertain_biosphere_exchanges(lca, cutoff)\n",
    "            # ch_inds = filter_characterization_exchanges(lca, cutoff)\n",
    "            cf_inds_uncertain = filter_uncertain_characterization_exchanges(lca, cutoff)\n",
    "            exchanges_dict = {\n",
    "                'tech': tech_inds_uncertain,\n",
    "                'bio': bio_inds_uncertain,\n",
    "                'cf': cf_inds_uncertain,\n",
    "            }\n",
    "            write_pickle(exchanges_dict, exchanges_dict_filepath)\n",
    "\n",
    "        num_params_all = len(tech_inds_uncertain) + len(bio_inds_uncertain) + len(cf_inds_uncertain)\n",
    "        subset_exchanges_dict_all = collect_uncertain_exchanges(exchanges_dict, num_params_all)\n",
    "        \n",
    "        subset_exchanges_dict = collect_uncertain_exchanges(exchanges_dict, num_params_ranking)\n",
    "\n",
    "        row_ind = 0\n",
    "        col_ind = 1\n",
    "        sdicts = {\n",
    "            'ranking': subset_exchanges_dict,\n",
    "            'all': subset_exchanges_dict_all,\n",
    "        }\n",
    "        data = {}\n",
    "        for sname, sdict in sdicts.items():\n",
    "            parameter_choice_dict = {}\n",
    "            for uncertain_exchange_type, exc_list in sdict.items():\n",
    "                params = model.uncertain_params[uncertain_exchange_type]\n",
    "                where_list = []\n",
    "                if uncertain_exchange_type != 'cf':\n",
    "                    for exc in exc_list:\n",
    "                        where = np.where(np.logical_and(\n",
    "                            params['row'] == exc[row_ind],\n",
    "                            params['col'] == exc[col_ind],\n",
    "                        ))[0]\n",
    "                        assert len(where)==1\n",
    "                        where_list.append(where[0])\n",
    "                else:\n",
    "                    for exc in exc_list:\n",
    "                        where = np.where(params['row'] == exc[row_ind])[0]\n",
    "                        assert len(where) == 1\n",
    "                        where_list.append(where[0])\n",
    "                where_list = sorted(where_list)\n",
    "                parameter_choice_dict[uncertain_exchange_type] = np.array(where_list)\n",
    "\n",
    "            parameter_choice_inf_tech = np.array(parameter_choice_dict['tech'])\n",
    "            parameter_choice_inf_bio  = np.array(parameter_choice_dict['bio']) + model.uncertain_exchange_lengths['tech']\n",
    "            parameter_choice_inf_cf   = np.array(parameter_choice_dict['cf']) + model.uncertain_exchange_lengths['tech'] + model.uncertain_exchange_lengths['bio']\n",
    "\n",
    "            parameter_choice_inf_graph = np.hstack(\n",
    "                [parameter_choice_inf_tech, parameter_choice_inf_bio, parameter_choice_inf_cf]\n",
    "            )\n",
    "            data[sname] = {\n",
    "                \"parameter_choice_dict\": parameter_choice_dict, \n",
    "                \"parameter_choice_inf_graph\": parameter_choice_inf_graph\n",
    "            }\n",
    "            write_pickle(data, filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir_sct = write_dir / 'supply_chain'\n",
    "\n",
    "data_all = {}\n",
    "# percentage of the total score, cutoff=0.005 means 0.5 percent\n",
    "cutoffs = np.array([1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5])\n",
    "nums_params_ranking = np.array([100,200,400,800,1600])\n",
    "cutoffs, nums_params_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlaps = {}\n",
    "overlaps_all = {}\n",
    "overlaps_ran = {}\n",
    "for cutoff in cutoffs:\n",
    "    print(\"--> {}\".format(cutoff))\n",
    "    data_all[cutoff] = {}\n",
    "    overlaps[cutoff] = {}\n",
    "    overlaps_all[cutoff] = {}\n",
    "    overlaps_ran[cutoff] = {}\n",
    "    for num_params_ranking in nums_params_ranking:\n",
    "#         print(num_params_ranking)\n",
    "        data_current = graph_traversal_screening(lca, model, write_dir_sct, cutoff, num_params_ranking)\n",
    "        data_all[cutoff][num_params_ranking] = data_current\n",
    "        \n",
    "        parameter_choice_inf_lsa = parameter_choice_rm_lowinf[inf_sorted[:num_params_ranking]]\n",
    "        parameter_choice_inf_lsa = np.sort(parameter_choice_inf_lsa)\n",
    "        \n",
    "        parameter_choice_inf_graph_all = data_current['all']['parameter_choice_inf_graph']\n",
    "        parameter_choice_inf_graph_ran = data_current['ranking']['parameter_choice_inf_graph']\n",
    "        \n",
    "        overlap1 = np.intersect1d(parameter_choice_inf_lsa, parameter_choice_inf_graph_all)\n",
    "        overlap2 = np.intersect1d(parameter_choice_inf_lsa, parameter_choice_inf_graph_ran)\n",
    "        \n",
    "        parameter_choice_inf_graph_all_tech = data_current['all']['parameter_choice_dict']['tech']\n",
    "        parameter_choice_inf_graph_all_bio  = data_current['all']['parameter_choice_dict']['bio']\n",
    "        parameter_choice_inf_graph_all_cf   = data_current['all']['parameter_choice_dict']['cf']\n",
    "        parameter_choice_inf_graph_ran_tech = data_current['ranking']['parameter_choice_dict']['tech']\n",
    "        parameter_choice_inf_graph_ran_bio  = data_current['ranking']['parameter_choice_dict']['bio']\n",
    "        parameter_choice_inf_graph_ran_cf   = data_current['ranking']['parameter_choice_dict']['cf']\n",
    "        \n",
    "        parameter_choice_inf_lsa_tech = parameter_choice_inf_lsa[\n",
    "            parameter_choice_inf_lsa<model.uncertain_exchange_lengths['tech']\n",
    "        ]\n",
    "        \n",
    "        parameter_choice_inf_lsa_bio  = parameter_choice_inf_lsa[\n",
    "            np.logical_and(\n",
    "                parameter_choice_inf_lsa >= model.uncertain_exchange_lengths['tech'],\n",
    "                parameter_choice_inf_lsa < model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "            )  \n",
    "        ] - model.uncertain_exchange_lengths['tech']\n",
    "        \n",
    "        parameter_choice_inf_lsa_cf = parameter_choice_inf_lsa[\n",
    "            parameter_choice_inf_lsa >= model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "        ] - model.uncertain_exchange_lengths['tech'] - model.uncertain_exchange_lengths['bio']\n",
    "        \n",
    "        overlap_all_tech = np.intersect1d(parameter_choice_inf_lsa_tech, parameter_choice_inf_graph_all_tech)\n",
    "        overlap_all_bio  = np.intersect1d(parameter_choice_inf_lsa_bio,  parameter_choice_inf_graph_all_bio)\n",
    "        overlap_all_cf   = np.intersect1d(parameter_choice_inf_lsa_cf,   parameter_choice_inf_graph_all_cf)\n",
    "        \n",
    "        overlap_ran_tech = np.intersect1d(parameter_choice_inf_lsa_tech, parameter_choice_inf_graph_ran_tech)\n",
    "        overlap_ran_bio  = np.intersect1d(parameter_choice_inf_lsa_bio,  parameter_choice_inf_graph_ran_bio)\n",
    "        overlap_ran_cf   = np.intersect1d(parameter_choice_inf_lsa_cf,   parameter_choice_inf_graph_ran_cf)\n",
    "        \n",
    "        overlaps[cutoff][num_params_ranking] = (len(parameter_choice_inf_graph_all), len(overlap1), len(overlap2))\n",
    "        overlaps_all[cutoff][num_params_ranking] = (\n",
    "            len(overlap_all_tech), len(overlap_all_bio), len(overlap_all_cf)\n",
    "        )\n",
    "        overlaps_ran[cutoff][num_params_ranking] = (\n",
    "            len(overlap_ran_tech), len(overlap_ran_bio), len(overlap_ran_cf)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(overlaps_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(overlaps_ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_current['ranking']['parameter_choice_dict']['tech'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_choice_inf_lsa_tech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1322 - 211)/21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "54.17*21.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1322/42.2 - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "211/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = parameter_choice_inf[parameter_choice_inf<model.uncertain_exchange_lengths['tech']]\n",
    "b = parameter_choice_inf_tech\n",
    "a.shape, b.shape, np.intersect1d(a,b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare our screening with graph traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_choice_inf_intersect = np.intersect1d(parameter_choice_inf, parameter_choice_inf_graph)\n",
    "len(parameter_choice_inf_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gsa_framework.convergence_robustness_validation import Validation\n",
    "\n",
    "default_uncertain_amounts = np.hstack([\n",
    "    v for v in model.default_uncertain_amounts.values()\n",
    "])\n",
    "\n",
    "iterations_validation = 300\n",
    "validation_seed = 100023423\n",
    "lca_scores_axis_title = r\"$\\text{LCA scores, [kg CO}_2\\text{-eq}]$\"\n",
    "if __name__ == \"__main__\":\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=default_uncertain_amounts,\n",
    "        write_dir=write_dir,\n",
    "        model_output_name=lca_scores_axis_title,\n",
    "    )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tag = \"SpearmanIndex\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parameter_choice_inf_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tag = \"GraphTraversal\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf_graph, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf_graph.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf_graph.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tag = \"SpearmanGraphIntersection\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf_intersect, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf_intersect.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf_intersect.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA for prioritized list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = \"protocol\"\n",
    "if option == \"graph\":\n",
    "    parameter_choice_inf_use = parameter_choice_inf_graph\n",
    "elif option == \"protocol\":\n",
    "    parameter_choice_inf_use = parameter_choice_inf\n",
    "\n",
    "parameter_choice_inf_tech = parameter_choice_inf_use[\n",
    "    parameter_choice_inf_use < model.uncertain_exchange_lengths['tech']\n",
    "]\n",
    "tech_inds = parameter_choice_inf_tech\n",
    "tech_params = model.uncertain_params['tech'][tech_inds]\n",
    "tech_where = model.uncertain_params_selected_where_dict['tech'][tech_inds]\n",
    "\n",
    "parameter_choice_inf_bio = parameter_choice_inf_use[\n",
    "    np.logical_and(\n",
    "        parameter_choice_inf_use >= model.uncertain_exchange_lengths['tech'],\n",
    "        parameter_choice_inf_use < model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "    )  \n",
    "]\n",
    "bio_inds = parameter_choice_inf_bio-model.uncertain_exchange_lengths['tech']\n",
    "bio_params = model.uncertain_params['bio'][bio_inds]\n",
    "bio_where = model.uncertain_params_selected_where_dict['bio'][bio_inds]\n",
    "\n",
    "parameter_choice_inf_cf = parameter_choice_inf_use[\n",
    "    parameter_choice_inf_use >= model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "]\n",
    "cf_inds = parameter_choice_inf_cf-model.uncertain_exchange_lengths['tech']-model.uncertain_exchange_lengths['bio']\n",
    "cf_params = model.uncertain_params['cf'][cf_inds]\n",
    "cf_where = model.uncertain_params_selected_where_dict['cf'][cf_inds]\n",
    "\n",
    "uncertain_params = {\n",
    "    'tech': tech_params,\n",
    "    'bio': bio_params,\n",
    "    'cf': cf_params,\n",
    "}\n",
    "uncertain_params_selected_where_dict = {\n",
    "    'tech': tech_where,\n",
    "    'bio': bio_where,\n",
    "    'cf': cf_where,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    model_ranking = LCAModelBase(\n",
    "        demand, \n",
    "        method, \n",
    "        uncertain_params, \n",
    "        uncertain_params_selected_where_dict,\n",
    "    )\n",
    "    gsa = SaltelliSobol(iterations=iterations_ranking, model=model_ranking, write_dir=write_dir)\n",
    "    S_salt = gsa.perform_gsa()\n",
    "    fig = gsa.plot_sa_results(S_salt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_Y = \"{}.{}{}\".format(gsa.filepath_Y.stem, option, gsa.filepath_Y.suffix)\n",
    "filepath_Y = gsa.filepath_Y.parent / filename_Y\n",
    "filepath_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X = gsa.generate_unitcube_samples(iterations_ranking)\n",
    "# Xr = model_ranking.rescale(X)\n",
    "# Y = model_ranking(Xr)\n",
    "# write_hdf5_array(Y, filepath_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence, robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.sensitivity_methods.saltelli_sobol import sobol_indices_stability\n",
    "from gsa_framework.convergence_robustness_validation import Convergence, Robustness\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_pickle\n",
    "\n",
    "num_bootstrap = 100\n",
    "num_steps = 50\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    gsa.filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")\n",
    "\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label,\n",
    "    gsa.sampling_label,\n",
    "    gsa.iterations,\n",
    "    conv.iterations_step,\n",
    "    num_bootstrap,\n",
    "    gsa.seed,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    Y = read_hdf5_array(gsa.filepath_Y).flatten()\n",
    "    S_dict_stability = sobol_indices_stability(\n",
    "        Y,\n",
    "        gsa.num_params,\n",
    "        conv.iterations_for_convergence,\n",
    "        num_bootstrap,\n",
    "        stability_seeds,\n",
    "    )\n",
    "    write_pickle(S_dict_stability, filepath_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For convergence, total order should be higher than first order, first order should be non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(num_params_ranking)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=S_salt['First order'],\n",
    "        mode=\"markers\",\n",
    "        name=\"First order\",\n",
    "        marker=dict(\n",
    "            color=\"blue\",\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=S_salt['Total order'],\n",
    "        mode=\"markers\",\n",
    "        name=\"Total order\",\n",
    "        marker=dict(\n",
    "            color=\"red\",\n",
    "            symbol=\"x\",\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Sobol indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Confidence intervals at last step for all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.utils_paper_plotting import *\n",
    "\n",
    "num_ranks = 20\n",
    "bootstrap_ranking_tag = 'paper2'\n",
    "stability_dicts = [S_dict_stability]\n",
    "st = Robustness(\n",
    "    stability_dicts,\n",
    "    write_dir,\n",
    "    num_ranks=num_ranks,\n",
    "    bootstrap_ranking_tag=bootstrap_ranking_tag,\n",
    "    num_params_screening=int(0.90 * gsa.num_params),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(num_params_ranking)\n",
    "\n",
    "sa_names = ['first', 'total']\n",
    "colors = {\n",
    "    'first': color_blue_tuple, \n",
    "    'total': color_blue_tuple,\n",
    "}\n",
    "opacity = 0.65\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles = sa_names,\n",
    ")\n",
    "\n",
    "col = 1\n",
    "\n",
    "for row, sa_name in enumerate(sa_names):\n",
    "    row += 1\n",
    "    color = colors[sa_name]\n",
    "    if sa_name == 'first':\n",
    "        y = S_salt['First order']\n",
    "    elif sa_name ==  'total':\n",
    "        y = S_salt['Total order']\n",
    "    width = st.confidence_intervals[sa_name][-1,:]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"markers\",\n",
    "            name=sa_name,\n",
    "            marker=dict(\n",
    "                color=color_orange_rgb,\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            error_y=dict(\n",
    "                type='data', # value of error bar given in data coordinates\n",
    "                symmetric=False,\n",
    "                array=width/2,\n",
    "                arrayminus=width/2,\n",
    "                visible=True,\n",
    "                color=color_blue_rgb,\n",
    "            )\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Sobol indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Max confidence invervals at all steps, $Stat_{indices}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opacity = 0.65\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles = sa_names,\n",
    ")\n",
    "\n",
    "col = 1\n",
    "for row, sa_name in enumerate(sa_names):\n",
    "    row += 1\n",
    "    showlegend = False\n",
    "    color = colors[sa_name]\n",
    "    x = st.iterations[sa_name]\n",
    "    y = np.zeros(len(x))\n",
    "    width = st.confidence_intervals_max[sa_name]\n",
    "    lower = y - width / 2\n",
    "    upper = y + width / 2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            showlegend=showlegend,\n",
    "            name = sa_name,\n",
    "            marker=dict(\n",
    "                color=\"rgba({},{},{},{})\".format(\n",
    "                    color[0],\n",
    "                    color[1],\n",
    "                    color[2],\n",
    "                    1,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    showlegend = False\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=lower,\n",
    "            mode=\"lines\",\n",
    "            opacity=opacity,\n",
    "            showlegend=False,\n",
    "            marker=dict(\n",
    "                color=\"rgba({},{},{},{})\".format(\n",
    "                    color[0],\n",
    "                    color[1],\n",
    "                    color[2],\n",
    "                    opacity,\n",
    "                ),\n",
    "            ),\n",
    "            line=dict(width=0),\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=upper,\n",
    "            showlegend=False,\n",
    "            line=dict(width=0),\n",
    "            mode=\"lines\",\n",
    "            fillcolor=\"rgba({},{},{},{})\".format(\n",
    "                color[0],\n",
    "                color[1],\n",
    "                color[2],\n",
    "                opacity,\n",
    "            ),\n",
    "            fill=\"tonexty\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "fig.update_xaxes(title='MC iterations')\n",
    "fig.update_yaxes(title='Max confidence interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = S_salt['Total order']\n",
    "total_argsort = np.argsort(total)[::-1]\n",
    "total_sorted = total[total_argsort]\n",
    "first_sorted = S_salt['First order'][total_argsort]\n",
    "width = st.confidence_intervals['total'][-1,:]\n",
    "width_sorted = width[total_argsort]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(total_sorted)),\n",
    "        y=total_sorted,\n",
    "        mode=\"markers\",\n",
    "        name=\"Total order\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_orange_rgb,\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            symmetric=False,\n",
    "            array=width_sorted/2,\n",
    "            arrayminus=width_sorted/2,\n",
    "            visible=True,\n",
    "            color=color_blue_rgb,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Total order indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_ranked = 23\n",
    "\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "\n",
    "len_tech = model.uncertain_exchange_lengths['tech']\n",
    "where_tech = np.where(parameter_choice_ranked<len_tech)[0]\n",
    "ind_tech = parameter_choice_ranked[where_tech]\n",
    "inf_tech_params = {\n",
    "    where_tech[i]: {\n",
    "        \"type\": \"tech\",\n",
    "        \"param\": model.uncertain_params['tech'][ind_tech[i]]\n",
    "    }\n",
    "    for i in range(len(where_tech))\n",
    "}\n",
    "\n",
    "len_bio = model.uncertain_exchange_lengths['bio']\n",
    "where_bio = np.where(np.logical_and(\n",
    "    parameter_choice_ranked>=len_tech,\n",
    "    parameter_choice_ranked<len_tech+len_bio,\n",
    "))[0]\n",
    "ind_bio = parameter_choice_ranked[where_bio]-len_tech\n",
    "inf_bio_params = {\n",
    "    where_bio[i]: {\n",
    "        \"type\": \"bio\",\n",
    "        \"param\": model.uncertain_params['bio'][ind_bio[i]]\n",
    "    }\n",
    "    for i in range(len(where_bio))\n",
    "}\n",
    "\n",
    "len_cf = model.uncertain_exchange_lengths['cf']\n",
    "where_cf = np.where(np.logical_and(\n",
    "    parameter_choice_ranked>=len_tech+len_bio,\n",
    "    parameter_choice_ranked<len_tech+len_bio+len_cf,\n",
    "))[0]\n",
    "ind_cf = parameter_choice_ranked[where_cf]-len_tech-len_bio\n",
    "inf_cf_params = {\n",
    "    where_cf[i]: {\n",
    "        \"type\": \"cf\",\n",
    "        \"param\": model.uncertain_params['cf'][ind_cf[i]]\n",
    "    }\n",
    "    for i in range(len(where_cf))\n",
    "}\n",
    "\n",
    "params = {**inf_tech_params, **inf_bio_params, **inf_cf_params}\n",
    "params = {k : params[k] for k in sorted(params)}\n",
    "\n",
    "TECH_IND = 0\n",
    "BIO_IND = 2\n",
    "distributions = {\n",
    "    sa.NormalUncertainty.id: 'normal',\n",
    "    sa.LognormalUncertainty.id: 'lognml',\n",
    "    sa.UniformUncertainty.id: 'unifrm',\n",
    "}\n",
    "\n",
    "for rank, dict_ in params.items():\n",
    "    exchange_type = dict_['type']\n",
    "    param = dict_['param']\n",
    "    row = param['row']\n",
    "    col = param['col']\n",
    "    print(\n",
    "        \"{:2d}. total={:5.3f}, {}, amount={:8.5f}, scale={:5.3f}\".format(\n",
    "            rank, \n",
    "            total_sorted[rank],\n",
    "            distributions[param['uncertainty_type']],\n",
    "            param['amount'],\n",
    "            param['scale'],\n",
    "        )\n",
    "    )      \n",
    "    if exchange_type=='tech':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[TECH_IND][row])\n",
    "        act_out = bd.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {}, {} \\n\".format(act_in['name'], act_in['unit'], act_in['location']))\n",
    "    elif exchange_type=='bio':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        act_out = bd.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {} \\n\".format(act_in['name'], act_in['unit']))\n",
    "    elif exchange_type=='cf':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        print(\"GWP of:    {} \\n\".format(act_in['name'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ranked = 24\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRanked.graph\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.visualization.plotting import *\n",
    "\n",
    "def plot_hist_val(Y_subset, parameter_choice_ranked):\n",
    "    bin_min = min(val.Y_all)\n",
    "    bin_max = max(val.Y_all)\n",
    "    fig = plot_histogram_Y1_Y2(\n",
    "        val.Y_all,\n",
    "        Y_subset,\n",
    "        bin_min=bin_min,\n",
    "        bin_max=bin_max,\n",
    "        num_bins=60,\n",
    "        trace_name1=\"All parameters vary\",\n",
    "        trace_name2=\"Only influential vary\",\n",
    "        color1=\"#636EFA\",\n",
    "        color2=\"#EF553B\",\n",
    "        opacity=0.65,\n",
    "        xaxes_title_text=val.model_output_name,\n",
    "        showtitle=True,\n",
    "    )\n",
    "    fig.update_yaxes(range=[0,25])\n",
    "    fig.write_image(\n",
    "        val.create_figure_Y_all_Y_inf_histogram_filepath(\n",
    "            parameter_choice_ranked.shape[0], tag, \"pdf\"\n",
    "        ).as_posix()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig_format = [\"pdf\"]\n",
    "spearman_yy = []\n",
    "num_ranked_max = 25\n",
    "num_ranked_arr = np.hstack(\n",
    "    [\n",
    "        np.arange(1,10),\n",
    "        np.arange(10,num_ranked_max,2)\n",
    "    ]\n",
    ")\n",
    "tag = \"TotalRanked.{}\".format(\"graph\")\n",
    "if __name__ == \"__main__\":\n",
    "    for num_ranked in num_ranked_arr:\n",
    "        print(num_ranked)\n",
    "        parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "        Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "        s, _ = spearmanr(val.Y_all, Y_subset)\n",
    "        spearman_yy.append(s)\n",
    "        fig=val.plot_correlation_Y_all_Y_inf(\n",
    "            Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag, fig_format=fig_format,\n",
    "        )\n",
    "        plot_hist_val(Y_subset, parameter_choice_ranked)\n",
    "        \n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=num_ranked_arr,\n",
    "        y=spearman_yy,\n",
    "        mode=\"markers+lines\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_blue_rgb,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Number of varying influential inputs')\n",
    "fig.update_yaxes(title='Spearman correlation between Y_all and Y_inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig_format = [\"pdf\"]\n",
    "spearman_yy = []\n",
    "num_ranked_max = 25\n",
    "num_ranked_arr = np.hstack(\n",
    "    [\n",
    "        np.arange(1,10),\n",
    "        np.arange(10,num_ranked_max,2)\n",
    "    ]\n",
    ")\n",
    "tag = \"TotalRanked.{}\".format(\"protocol\")\n",
    "if __name__ == \"__main__\":\n",
    "    for num_ranked in num_ranked_arr:\n",
    "        print(num_ranked)\n",
    "        parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "        Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "        s, _ = spearmanr(val.Y_all, Y_subset)\n",
    "        spearman_yy.append(s)\n",
    "        fig=val.plot_correlation_Y_all_Y_inf(\n",
    "            Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag, fig_format=fig_format,\n",
    "        )\n",
    "        plot_hist_val(Y_subset, parameter_choice_ranked)\n",
    "        \n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=num_ranked_arr,\n",
    "        y=spearman_yy,\n",
    "        mode=\"markers+lines\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_blue_rgb,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Number of varying influential inputs')\n",
    "fig.update_yaxes(title='Spearman correlation between Y_all and Y_inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ranked = 9\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "parameter_choice_ranked_inv = np.setdiff1d(np.arange(model.num_params), parameter_choice_ranked)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRankedInv\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked_inv, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ranked = 23\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "parameter_choice_ranked_inv = np.setdiff1d(np.arange(model.num_params), parameter_choice_ranked)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRankedInv\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked_inv, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:protocol-dev-py38]",
   "language": "python",
   "name": "conda-env-protocol-dev-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
