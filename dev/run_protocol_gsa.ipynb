{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import stats_arrays as sa\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from gsa_framework.models.life_cycle_assessment import LCAModelBase\n",
    "from gsa_framework.sensitivity_analysis.correlations import Correlations\n",
    "from gsa_framework.sensitivity_analysis.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.utils import read_pickle, write_pickle, write_hdf5_array, read_hdf5_array\n",
    "from setups_paper_gwp import setup_corr, setup_lca_model_protocol\n",
    "# from gsa_framework.utils import read_hdf5_array, write_hdf5_array\n",
    "# from gsa_framework.visualization.plotting import plot_correlation_Y1_Y2, plot_histogram_Y1_Y2\n",
    "\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unitcube samples ->    0.022 s\n",
      "Rescaled samples ->    0.001 s\n",
      "Model outputs    ->    0.000 s\n",
      "GSA indices      ->    0.021 s\n",
      "Total GSA time   ->    0.045 s \n",
      "\n",
      "LCA score is 211.57670115973556\n",
      "Total number of uncertain exchanges is 408722\n",
      "   tech=186602, bio=222049, cf=71\n"
     ]
    }
   ],
   "source": [
    "path_base = Path('/data/user/kim_a')\n",
    "\n",
    "# LCA model\n",
    "bd.projects.set_current(\"GSA for protocol\")\n",
    "co = bd.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"Food\" in act[\"name\"]]\n",
    "assert len(demand_act) == 1\n",
    "demand_act = demand_act[0]\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "\n",
    "num_params = 20000\n",
    "iter_corr = 4*num_params\n",
    "gsa_corr = setup_corr(num_params, iter_corr, setup_lca_model_protocol, path_base)\n",
    "S = gsa_corr.perform_gsa()\n",
    "spearman = S['spearman']\n",
    "spearman_sorted = np.argsort(np.abs(spearman))[::-1]\n",
    "\n",
    "model, write_dir, gsa_seed = setup_lca_model_protocol(\n",
    "    path_base,\n",
    "    num_params=None,\n",
    "    write_dir=None,\n",
    ")\n",
    "\n",
    "write_dir_arr = write_dir / \"arrays\"\n",
    "write_dir_sct = write_dir / \"supply_chain\"\n",
    "\n",
    "path_lsa = model.write_dir / \"LSA_scores\"\n",
    "path_lsa_include_inds_bio = path_lsa / \"include_inds_bio.pickle\"\n",
    "include_inds_bio = read_pickle(path_lsa_include_inds_bio)\n",
    "path_lsa_include_inds_cf = path_lsa / \"include_inds_cf.pickle\"\n",
    "include_inds_cf = read_pickle(path_lsa_include_inds_cf)\n",
    "\n",
    "include_inds_tech_forX = np.arange(model.uncertain_exchange_lengths['tech'])\n",
    "include_inds_bio_forX  = model.uncertain_exchange_lengths['tech'] + include_inds_bio\n",
    "include_inds_cf_forX   = model.uncertain_exchange_lengths['tech'] + \\\n",
    "                         model.uncertain_exchange_lengths['bio']  + include_inds_cf\n",
    "parameter_choice_rm_noninf = np.hstack(\n",
    "    [include_inds_tech_forX, include_inds_bio_forX, include_inds_cf_forX]\n",
    ")\n",
    "\n",
    "scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\", model.uncertain_exchanges_types)\n",
    "num_params_lsa = 20000 #10000\n",
    "where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "num_params_ranking = 200\n",
    "gsa_seed_ranking = 555666\n",
    "iterations_ranking = num_params_ranking * 1600\n",
    "parameter_choice_inf_lsa = parameter_choice_rm_lowinf[spearman_sorted[:num_params_ranking]]\n",
    "parameter_choice_inf_lsa = np.sort(parameter_choice_inf_lsa)\n",
    "\n",
    "# fp = write_dir / \"arrays\" / \"parameter_choice_rm_lowinf.pickle\"\n",
    "# write_pickle(parameter_choice_rm_lowinf, fp)\n",
    "\n",
    "# fp = write_dir / \"arrays\" / \"model.pickle\"\n",
    "# write_pickle(model, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph traversal screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "\n",
    "from dev.utils_graph_traversal import \\\n",
    "    filter_uncertain_technosphere_exchanges, \\\n",
    "    filter_uncertain_biosphere_exchanges, \\\n",
    "    filter_uncertain_characterization_exchanges, \\\n",
    "    collect_uncertain_exchanges\n",
    "\n",
    "bd.projects.set_current(\"GSA for protocol\")\n",
    "co = bd.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"Food\" in act[\"name\"]]\n",
    "assert len(demand_act) == 1\n",
    "demand_act = demand_act[0]\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "lca = bc.LCA(demand, method)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "\n",
    "def graph_traversal_screening(lca, model, write_dir, cutoff, num_params_ranking):\n",
    "    \n",
    "    cutoff_str = '%.2E' % Decimal(cutoff)\n",
    "    filename = \"cutoff{}.params{}.pickle\".format(cutoff_str, num_params_ranking)\n",
    "    filepath = write_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        data = read_pickle(filepath)\n",
    "    else:\n",
    "        exchanges_dict_filename = \"exchanges_dict.cutoff{}.pickle\".format(cutoff_str)\n",
    "        exchanges_dict_filepath = write_dir / exchanges_dict_filename\n",
    "        if exchanges_dict_filepath.exists():\n",
    "            exchanges_dict = read_pickle(exchanges_dict_filepath)\n",
    "            tech_inds_uncertain = exchanges_dict['tech']\n",
    "            bio_inds_uncertain = exchanges_dict['bio']\n",
    "            cf_inds_uncertain = exchanges_dict['cf']\n",
    "        else:\n",
    "            # tech_inds = filter_technosphere_exchanges(lca, cutoff)\n",
    "            tech_inds_uncertain = filter_uncertain_technosphere_exchanges(lca, cutoff, 1e8)\n",
    "            # bio_inds  = filter_biosphere_exchanges(lca, cutoff)\n",
    "            bio_inds_uncertain = filter_uncertain_biosphere_exchanges(lca, cutoff)\n",
    "            # ch_inds = filter_characterization_exchanges(lca, cutoff)\n",
    "#             cf_inds_uncertain = filter_uncertain_characterization_exchanges(lca, 0)\n",
    "#             print(cf_inds_uncertain)\n",
    "            cf_inds_uncertain_temp = lca.cf_params[lca.cf_params['uncertainty_type']>1]['row']\n",
    "            cf_inds_uncertain_temp = np.sort(cf_inds_uncertain_temp)\n",
    "            cf_inds_uncertain = [(row, None, np.inf) for row in cf_inds_uncertain_temp]\n",
    "            exchanges_dict = {\n",
    "                'tech': tech_inds_uncertain,\n",
    "                'bio': bio_inds_uncertain,\n",
    "                'cf': cf_inds_uncertain,\n",
    "            }\n",
    "            write_pickle(exchanges_dict, exchanges_dict_filepath)\n",
    "\n",
    "        num_params_all = len(tech_inds_uncertain) + len(bio_inds_uncertain) + len(cf_inds_uncertain)\n",
    "        subset_exchanges_dict_all = collect_uncertain_exchanges(exchanges_dict, num_params_all)\n",
    "        \n",
    "        subset_exchanges_dict = collect_uncertain_exchanges(exchanges_dict, num_params_ranking)\n",
    "\n",
    "        row_ind = 0\n",
    "        col_ind = 1\n",
    "        sdicts = {\n",
    "            'ranking': subset_exchanges_dict,\n",
    "            'all': subset_exchanges_dict_all,\n",
    "        }\n",
    "        data = {}\n",
    "        for sname, sdict in sdicts.items():\n",
    "            parameter_choice_dict = {}\n",
    "            for uncertain_exchange_type, exc_list in sdict.items():\n",
    "                params = model.uncertain_params[uncertain_exchange_type]\n",
    "                where_list = []\n",
    "                if uncertain_exchange_type != 'cf':\n",
    "                    for exc in exc_list:\n",
    "                        where = np.where(np.logical_and(\n",
    "                            params['row'] == exc[row_ind],\n",
    "                            params['col'] == exc[col_ind],\n",
    "                        ))[0]\n",
    "                        assert len(where)==1\n",
    "                        where_list.append(where[0])\n",
    "                else:\n",
    "                    for exc in exc_list:\n",
    "                        where = np.where(params['row'] == exc[row_ind])[0]\n",
    "                        assert len(where) == 1\n",
    "                        where_list.append(where[0])\n",
    "                where_list = sorted(where_list)\n",
    "                parameter_choice_dict[uncertain_exchange_type] = np.array(where_list)\n",
    "\n",
    "            parameter_choice_inf_tech = np.array(parameter_choice_dict['tech'])\n",
    "            parameter_choice_inf_bio  = np.array(parameter_choice_dict['bio']) + model.uncertain_exchange_lengths['tech']\n",
    "            parameter_choice_inf_cf   = np.array(parameter_choice_dict['cf']) + model.uncertain_exchange_lengths['tech'] + model.uncertain_exchange_lengths['bio']\n",
    "\n",
    "            parameter_choice_inf_graph = np.hstack(\n",
    "                [parameter_choice_inf_tech, parameter_choice_inf_bio, parameter_choice_inf_cf]\n",
    "            )\n",
    "            data[sname] = {\n",
    "                \"parameter_choice_dict\": parameter_choice_dict, \n",
    "                \"parameter_choice_inf_graph\": parameter_choice_inf_graph\n",
    "            }\n",
    "            write_pickle(data, filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 0.01\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "--> 0.001\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "--> 0.0001\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "option_step3 = \"without_3\"\n",
    "write_dir_sct_with_3 = write_dir / 'supply_chain'\n",
    "write_dir_sct_without_3 = write_dir / 'supply_chain_without_step_3'\n",
    "if option_step3 == \"with_3\":\n",
    "    write_dir_sct = write_dir_sct_with_3\n",
    "elif option_step3 == \"without_3\":\n",
    "    write_dir_sct = write_dir_sct_without_3    \n",
    "    \n",
    "data_all = {}\n",
    "# percentage of the total score, cutoff=0.005 means 0.5 percent\n",
    "cutoffs = np.array([1e-2, 1e-3, 1e-4])\n",
    "nums_params_ranking = np.array([100,200,400,800,1600])\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    print(\"--> {}\".format(cutoff))\n",
    "    data_all[cutoff] = {}\n",
    "    for num_params_ranking in nums_params_ranking:\n",
    "        data_current = graph_traversal_screening(lca, model, write_dir_sct, cutoff, num_params_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of screening for LSA and SCT with different num_params_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client, LocalCluster\n",
    "# from dask_jobqueue import SLURMCluster\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# import dask\n",
    "\n",
    "# which_pc = \"merlin_protocol_gsa\"\n",
    "# if 'merlin' in which_pc:\n",
    "#     path_dask_logs = Path('/data/user/kim_a/dask_logs')\n",
    "#     path_dask_logs.mkdir(parents=True, exist_ok=True)\n",
    "#     cluster = SLURMCluster(cores     = 8,\n",
    "#                            memory    =\"40GB\", \n",
    "#                            walltime  = '02:00:00',\n",
    "#                            interface ='ib0',\n",
    "#                            local_directory = path_dask_logs.as_posix(),\n",
    "#                            log_directory   = path_dask_logs.as_posix(),\n",
    "#                            queue=\"daily\",\n",
    "#                            ) \n",
    "# elif 'local' in which_pc:\n",
    "#     cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_workers = 10\n",
    "# cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_per_worker = dask.delayed(val.get_influential_Y_from_parameter_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.convergence_robustness_validation import Validation\n",
    "\n",
    "default_uncertain_amounts = np.hstack([\n",
    "    v for v in model.default_uncertain_amounts.values()\n",
    "])\n",
    "\n",
    "iterations_validation = 2000\n",
    "validation_seed = 100023423\n",
    "lca_scores_axis_title = r\"$\\text{LCIA scores, [kg CO}_2\\text{-eq}]$\"\n",
    "if __name__ == \"__main__\":\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=default_uncertain_amounts,\n",
    "        write_dir=write_dir,\n",
    "        model_output_name=lca_scores_axis_title,\n",
    "    )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "400\n",
      "800\n",
      "1600\n",
      "CPU times: user 19h 52min 38s, sys: 35min 28s, total: 20h 28min 7s\n",
      "Wall time: 1h 12min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nums_params_ranking = [100,200,400,800,1600]\n",
    "cutoff = 1e-4\n",
    "    \n",
    "model_evals = []\n",
    "for num_params_ranking in nums_params_ranking:\n",
    "    print(num_params_ranking)\n",
    "#     parameter_choice_inf_lsa = parameter_choice_rm_lowinf[inf_sorted[:num_params_ranking]]\n",
    "#     parameter_choice_inf_lsa = np.sort(parameter_choice_inf_lsa)\n",
    "#     tag = \"localSA\"\n",
    "#     model_eval = task_per_worker(influential_inputs=parameter_choice_inf_lsa, tag=tag)\n",
    "#     model_evals.append(model_eval)\n",
    "#     Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf_lsa, tag=tag)\n",
    "    \n",
    "    tag = 'sct_without_3'\n",
    "    data = graph_traversal_screening(lca, model, write_dir_sct, cutoff, num_params_ranking)\n",
    "    parameter_choice_inf_sct = data['ranking'][\"parameter_choice_inf_graph\"]\n",
    "#     model_eval = task_per_worker(influential_inputs=parameter_choice_inf_lsa, tag=tag)\n",
    "#     model_evals.append(model_eval)\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf_sct, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA results for paper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1e-4\n",
    "num_params_ranking = 200\n",
    "data = graph_traversal_screening(lca, model, write_dir_sct, cutoff, num_params_ranking)\n",
    "parameter_choice_inf_sct = data['ranking']['parameter_choice_inf_graph']\n",
    "\n",
    "print(parameter_choice_inf_sct.shape, parameter_choice_inf_lsa.shape)\n",
    "np.intersect1d(parameter_choice_inf_sct, parameter_choice_inf_lsa).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = \"sct\"\n",
    "if option == \"sct\":\n",
    "    parameter_choice_inf_use = parameter_choice_inf_sct\n",
    "elif option == \"localSA\":\n",
    "    parameter_choice_inf_use = parameter_choice_inf_lsa\n",
    "\n",
    "def get_parameters_tech_bio_cf(parameter_choice, model):\n",
    "    parameter_choice_inf_tech = parameter_choice[\n",
    "        parameter_choice < model.uncertain_exchange_lengths['tech']\n",
    "    ]\n",
    "    tech_inds = parameter_choice_inf_tech\n",
    "    tech_params = model.uncertain_params['tech'][tech_inds]\n",
    "    tech_where = model.uncertain_params_selected_where_dict['tech'][tech_inds]\n",
    "\n",
    "    parameter_choice_inf_bio = parameter_choice[\n",
    "        np.logical_and(\n",
    "            parameter_choice >= model.uncertain_exchange_lengths['tech'],\n",
    "            parameter_choice < model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "        )  \n",
    "    ]\n",
    "    bio_inds = parameter_choice_inf_bio-model.uncertain_exchange_lengths['tech']\n",
    "    bio_params = model.uncertain_params['bio'][bio_inds]\n",
    "    bio_where = model.uncertain_params_selected_where_dict['bio'][bio_inds]\n",
    "\n",
    "    parameter_choice_inf_cf = parameter_choice[\n",
    "        parameter_choice >= model.uncertain_exchange_lengths['bio']+model.uncertain_exchange_lengths['tech'],\n",
    "    ]\n",
    "    cf_inds = parameter_choice_inf_cf-model.uncertain_exchange_lengths['tech']-model.uncertain_exchange_lengths['bio']\n",
    "    cf_params = model.uncertain_params['cf'][cf_inds]\n",
    "    cf_where = model.uncertain_params_selected_where_dict['cf'][cf_inds]\n",
    "\n",
    "    uncertain_params = {\n",
    "        'tech': tech_params,\n",
    "        'bio': bio_params,\n",
    "        'cf': cf_params,\n",
    "    }\n",
    "    uncertain_params_selected_where_dict = {\n",
    "        'tech': tech_where,\n",
    "        'bio': bio_where,\n",
    "        'cf': cf_where,    \n",
    "    }\n",
    "    return uncertain_params, uncertain_params_selected_where_dict \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    uncertain_params, uncertain_params_selected_where_dict = get_parameters_tech_bio_cf(\n",
    "        parameter_choice_inf_use, model\n",
    "    )\n",
    "    model_ranking = LCAModelBase(\n",
    "        demand, \n",
    "        method, \n",
    "        uncertain_params, \n",
    "        uncertain_params_selected_where_dict,\n",
    "    )\n",
    "    gsa = SaltelliSobol(iterations=iterations_ranking, model=model_ranking, write_dir=write_dir)\n",
    "#     S_salt = gsa.perform_gsa()\n",
    "#     fig = gsa.plot_sa_results(S_salt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_Y_saltelli_sct = write_dir_arr / \"Y.saltelliSampling.319968.None.sct.hdf5\"\n",
    "filepath_Y_saltelli_lsa = write_dir_arr / \"Y.saltelliSampling.319968.None.localSA.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.sensitivity_methods.saltelli_sobol import sobol_indices\n",
    "\n",
    "S_sct = sobol_indices(filepath_Y_saltelli_sct, num_params_ranking)\n",
    "S_lsa = sobol_indices(filepath_Y_saltelli_lsa, num_params_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# filename_Y = \"{}.{}{}\".format(gsa.filepath_Y.stem, option, gsa.filepath_Y.suffix)\n",
    "# filepath_Y = gsa.filepath_Y.parent / filename_Y\n",
    "# filepath_Y\n",
    "\n",
    "# X = gsa.generate_unitcube_samples(iterations_ranking)\n",
    "# Xr = model_ranking.rescale(X)\n",
    "# Y = model_ranking(Xr)\n",
    "# write_hdf5_array(Y, filepath_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Validation for 1 to 20 inputs, LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# option = 'sct'\n",
    "if option == 'localSA':\n",
    "    total = S_lsa['Total order']\n",
    "    parameter_choice_inf = parameter_choice_inf_lsa\n",
    "elif option == 'sct':\n",
    "    total = S_sct['Total order']\n",
    "    parameter_choice_inf = parameter_choice_inf_sct\n",
    "    \n",
    "total_argsort = np.argsort(total)[::-1]\n",
    "\n",
    "# spearman_yy = []\n",
    "# num_ranked_max = 20\n",
    "# num_ranked_arr = np.arange(1,num_ranked_max+1)\n",
    "# tag = \"TotalRanked.{}\".format(option)\n",
    "# if __name__ == \"__main__\":\n",
    "#     for num_ranked in num_ranked_arr:\n",
    "#         print(num_ranked)\n",
    "#         parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "#         Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "#         s, _ = spearmanr(val.Y_all, Y_subset)\n",
    "#         spearman_yy.append(s)\n",
    "        \n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=num_ranked_arr,\n",
    "#         y=spearman_yy,\n",
    "#         mode=\"markers+lines\",\n",
    "#         showlegend=False,\n",
    "# #         marker_color = color_blue_rgb,\n",
    "#     ),\n",
    "# )\n",
    "# fig.update_xaxes(title='Number of varying influential inputs')\n",
    "# fig.update_yaxes(title='Spearman correlation between Y_all and Y_inf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_ranked = 20\n",
    "# parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "# uparams_ranked, uparams_where_dict_ranked = get_parameters_tech_bio_cf(\n",
    "#     parameter_choice_ranked, model\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 1: Change uncertainties of bio flows to lognormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_to_lognormal_inds = [0,1,4,6]\n",
    "# # 1. Bio_params\n",
    "# dt = model.lca.bio_params.dtype\n",
    "# uncertain_bio_params = model.lca.bio_params[model.lca.bio_params['uncertainty_type']>1]\n",
    "# bio_params_copy = deepcopy(np.array([a for a in model.lca.bio_params], dtype = dt))\n",
    "# bio_params_modified = deepcopy(np.array([a for a in model.lca.bio_params], dtype = dt))\n",
    "\n",
    "# ## change normal to lognormal\n",
    "# for ind in bio_to_lognormal_inds:\n",
    "#     bio_ind = uparams_where_dict_ranked['bio'][ind]\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "#     bio_params_modified[bio_ind][\"uncertainty_type\"] = sa.LognormalUncertainty.id\n",
    "#     bio_params_modified[bio_ind]['loc'] = np.log(bio_params_copy[bio_ind]['loc'])\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "    \n",
    "# uncertain_bio_params_modified_where = np.where(bio_params_modified['uncertainty_type']>1)[0]\n",
    "# uncertain_bio_params_modified  = bio_params_modified[uncertain_bio_params_modified_where]\n",
    "\n",
    "# uncertain_tech_params_modified_where = model.uncertain_params_selected_where_dict['tech']\n",
    "# uncertain_tech_params_modified = model.lca.tech_params[uncertain_tech_params_modified_where]\n",
    "\n",
    "# uncertain_cf_params_modified_where = model.uncertain_params_selected_where_dict['cf']\n",
    "# uncertain_cf_params_modified = model.lca.cf_params[uncertain_cf_params_modified_where]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2: Change uncertainties of bio flows to lognormal and reduce scale 2 times in all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_tech_inds = np.arange(uparams_ranked['tech'].shape[0])\n",
    "# # 1. Tech_params\n",
    "# dt = model.lca.tech_params.dtype\n",
    "# uncertain_tech_params = model.lca.tech_params[model.lca.tech_params['uncertainty_type']>1]\n",
    "# tech_params_copy = deepcopy(np.array([a for a in model.lca.tech_params], dtype = dt))\n",
    "# tech_params_modified = deepcopy(np.array([a for a in model.lca.tech_params], dtype = dt))\n",
    "\n",
    "# ## Reduce twice\n",
    "# for ind in reduce_tech_inds:\n",
    "#     tech_ind = uparams_where_dict_ranked['tech'][ind]\n",
    "#     print(tech_params_modified[tech_ind])\n",
    "#     assert tech_params_modified[tech_ind][\"uncertainty_type\"] == sa.LognormalUncertainty.id\n",
    "#     tech_params_modified[tech_ind]['scale'] = tech_params_copy[tech_ind]['scale'] / 2\n",
    "#     print(tech_params_modified[tech_ind])\n",
    "    \n",
    "# uncertain_tech_params_modified_where = np.where(tech_params_modified['uncertainty_type']>1)[0]\n",
    "# uncertain_tech_params_modified  = tech_params_modified[uncertain_tech_params_modified_where]\n",
    "\n",
    "# reduce_cf_inds = np.arange(uparams_ranked['cf'].shape[0])\n",
    "# # 3. CF_params\n",
    "# dt = model.lca.cf_params.dtype\n",
    "# uncertain_cf_params = model.lca.cf_params[model.lca.cf_params['uncertainty_type']>1]\n",
    "# cf_params_copy = deepcopy(np.array([a for a in model.lca.cf_params], dtype = dt))\n",
    "# cf_params_modified = deepcopy(np.array([a for a in model.lca.cf_params], dtype = dt))\n",
    "\n",
    "# ## Reduce twice\n",
    "# for ind in reduce_cf_inds:\n",
    "#     cf_ind = uparams_where_dict_ranked['cf'][ind]\n",
    "#     print(cf_params_modified[cf_ind])\n",
    "#     assert cf_params_modified[cf_ind][\"uncertainty_type\"] == sa.NormalUncertainty.id\n",
    "#     cf_params_modified[cf_ind]['scale'] = cf_params_copy[cf_ind]['scale'] / 2\n",
    "#     print(cf_params_modified[cf_ind])\n",
    "    \n",
    "# uncertain_cf_params_modified_where = np.where(cf_params_modified['uncertainty_type']>1)[0]\n",
    "# uncertain_cf_params_modified  = cf_params_modified[uncertain_cf_params_modified_where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Bio_params\n",
    "# dt = model.lca.bio_params.dtype\n",
    "# uncertain_bio_params = model.lca.bio_params[model.lca.bio_params['uncertainty_type']>1]\n",
    "# bio_params_copy = deepcopy(np.array([a for a in model.lca.bio_params], dtype = dt))\n",
    "# bio_params_modified = deepcopy(np.array([a for a in model.lca.bio_params], dtype = dt))\n",
    "\n",
    "# ## change normal to lognormal\n",
    "# bio_to_lognormal_inds = [0,1,4,6]\n",
    "# for ind in bio_to_lognormal_inds:\n",
    "#     bio_ind = uparams_where_dict_ranked['bio'][ind]\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "#     bio_params_modified[bio_ind][\"uncertainty_type\"] = sa.LognormalUncertainty.id\n",
    "#     bio_params_modified[bio_ind]['loc'] = np.log(bio_params_copy[bio_ind]['loc'])\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "\n",
    "# reduce_bio_inds = [2,3,5,7,8,9]\n",
    "# ## Reduce twice\n",
    "# for ind in reduce_bio_inds:\n",
    "#     bio_ind = uparams_where_dict_ranked['bio'][ind]\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "#     assert bio_params_modified[bio_ind][\"uncertainty_type\"] == sa.LognormalUncertainty.id\n",
    "#     bio_params_modified[bio_ind]['scale'] = bio_params_copy[bio_ind]['scale'] / 2\n",
    "#     print(bio_params_modified[bio_ind])\n",
    "    \n",
    "# uncertain_bio_params_modified_where = np.where(bio_params_modified['uncertainty_type']>1)[0]\n",
    "# uncertain_bio_params_modified  = bio_params_modified[uncertain_bio_params_modified_where]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp: Run MC with narrowed params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# option = 'exp2'\n",
    "# if option == 'exp1':\n",
    "#     tag = 'BioModified_normal.exp1'\n",
    "# elif option == 'exp2':\n",
    "#     tag = '20Reduced_scale2.exp2'\n",
    "\n",
    "# uparams_narrow = {\n",
    "#     'tech': uncertain_tech_params_modified,\n",
    "#     'bio': uncertain_bio_params_modified,\n",
    "#     'cf': uncertain_cf_params_modified,\n",
    "# }\n",
    "# uparams_where_dict_narrow = {\n",
    "#     'tech':  uncertain_tech_params_modified_where,\n",
    "#     'bio':   uncertain_bio_params_modified_where,\n",
    "#     'cf':   uncertain_cf_params_modified_where,\n",
    "# }\n",
    "\n",
    "# model_narrow = LCAModelBase(\n",
    "#     demand,\n",
    "#     method,\n",
    "#     uncertain_params = uparams_narrow,\n",
    "#     uncertain_params_selected_where_dict=uparams_where_dict_narrow,\n",
    "# )\n",
    "\n",
    "# fp_Xr = \"/data/user/kim_a/protocol_gsa/arrays/validation.X.rescaled.all.{}.{}.hdf5\".format(\n",
    "#     iterations_validation, validation_seed\n",
    "# )\n",
    "# fp_Y_narrow = \"/data/user/kim_a/protocol_gsa/arrays/validation.Y.narrow.{}.{}.{}.hdf5\".format(\n",
    "#     iterations_validation, validation_seed, tag\n",
    "# )\n",
    "# fp_Y_narrow = Path(fp_Y_narrow)\n",
    "# Xr_prev = read_hdf5_array(fp_Xr)\n",
    "\n",
    "# if not fp_Y_narrow.exists():\n",
    "#     np.random.seed(validation_seed)\n",
    "#     X = np.random.rand(iterations_validation, model_narrow.num_params)\n",
    "#     Xr = model_narrow.rescale(X)\n",
    "#     del X\n",
    "#     Y_narrow = model_narrow(Xr)\n",
    "#     write_hdf5_array(Y_narrow, fp_Y_narrow)\n",
    "# else:\n",
    "#     Y_narrow = read_hdf5_array(fp_Y_narrow).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gsa_framework.visualization.plotting import plot_histogram_Y1_Y2\n",
    "\n",
    "# ii = parameter_choice_ranked[19]\n",
    "# Y1 = Xr_prev[:,ii]\n",
    "# Y2 = Xr[:,ii]\n",
    "# plot_histogram_Y1_Y2(Y1, Y2)\n",
    "# plot_histogram_Y1_Y2(val.Y_all, Y_narrow)\n",
    "# np.std(val.Y_all) / np.std(Y_narrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA results for SI of paper2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence, robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_Y = gsa.filepath_Y.parent / gsa.filepath_Y.name.replace(\"None\", \"None.{}\".format(option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.sensitivity_methods.saltelli_sobol import sobol_indices_stability\n",
    "from gsa_framework.convergence_robustness_validation import Convergence, Robustness\n",
    "from gsa_framework.utils import read_hdf5_array, read_pickle, write_pickle\n",
    "\n",
    "num_bootstrap = 1000\n",
    "num_steps = 50\n",
    "\n",
    "# Convergence class\n",
    "conv = Convergence(\n",
    "    filepath_Y,\n",
    "    gsa.num_params,\n",
    "    gsa.generate_gsa_indices,\n",
    "    gsa.gsa_label,\n",
    "    gsa.write_dir,\n",
    "    num_steps=num_steps,\n",
    ")\n",
    "np.random.seed(gsa.seed)\n",
    "stability_seeds = np.random.randint(\n",
    "    low=0,\n",
    "    high=2147483647,\n",
    "    size=(len(conv.iterations_for_convergence), num_bootstrap),\n",
    ")\n",
    "\n",
    "filename_S = \"stability.S.{}.{}.{}Step{}.{}.{}.{}.pickle\".format(\n",
    "    gsa.gsa_label,\n",
    "    gsa.sampling_label,\n",
    "    gsa.iterations,\n",
    "    conv.iterations_step,\n",
    "    num_bootstrap,\n",
    "    gsa.seed,\n",
    "    option,\n",
    ")\n",
    "filepath_S = gsa.write_dir / \"arrays\" / filename_S\n",
    "if filepath_S.exists():\n",
    "    print(\"--> {} already exists\".format(filename_S))\n",
    "    S_dict_stability = read_pickle(filepath_S)\n",
    "else:\n",
    "    Y = read_hdf5_array(filepath_Y).flatten()\n",
    "    S_dict_stability = sobol_indices_stability(\n",
    "        Y,\n",
    "        gsa.num_params,\n",
    "        conv.iterations_for_convergence,\n",
    "        num_bootstrap,\n",
    "        stability_seeds,\n",
    "    )\n",
    "    write_pickle(S_dict_stability, filepath_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For convergence, total order should be higher than first order, first order should be non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option == 'localSA':\n",
    "    S_salt = S_lsa\n",
    "elif option == 'sct':\n",
    "    S_salt = S_sct\n",
    "\n",
    "x = np.arange(num_params_ranking)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=S_salt['First order'],\n",
    "        mode=\"markers\",\n",
    "        name=\"First order\",\n",
    "        marker=dict(\n",
    "            color=\"blue\",\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=S_salt['Total order'],\n",
    "        mode=\"markers\",\n",
    "        name=\"Total order\",\n",
    "        marker=dict(\n",
    "            color=\"red\",\n",
    "            symbol=\"x\",\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Sobol indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Confidence intervals at last step for all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.utils_paper_plotting import *\n",
    "\n",
    "num_ranks = 20\n",
    "stability_dicts = [S_dict_stability]\n",
    "st = Robustness(\n",
    "    stability_dicts,\n",
    "    write_dir,\n",
    "    num_ranks=num_ranks,\n",
    "    num_params_screening=int(0.90 * num_params_ranking),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(num_params_ranking)\n",
    "\n",
    "sa_names = ['first', 'total']\n",
    "colors = {\n",
    "    'first': color_blue_tuple, \n",
    "    'total': color_blue_tuple,\n",
    "}\n",
    "opacity = 0.65\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles = sa_names,\n",
    ")\n",
    "\n",
    "col = 1\n",
    "\n",
    "for row, sa_name in enumerate(sa_names):\n",
    "    row += 1\n",
    "    color = colors[sa_name]\n",
    "    if sa_name == 'first':\n",
    "        y = S_salt['First order']\n",
    "    elif sa_name ==  'total':\n",
    "        y = S_salt['Total order']\n",
    "    width = st.confidence_intervals[sa_name][-1,:]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"markers\",\n",
    "            name=sa_name,\n",
    "            marker=dict(\n",
    "                color=color_orange_rgb,\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            error_y=dict(\n",
    "                type='data', # value of error bar given in data coordinates\n",
    "                symmetric=False,\n",
    "                array=width/2,\n",
    "                arrayminus=width/2,\n",
    "                visible=True,\n",
    "                color=color_blue_rgb,\n",
    "            )\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Sobol indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Max confidence invervals at all steps, $Stat_{indices}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opacity = 0.65\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles = sa_names,\n",
    ")\n",
    "\n",
    "col = 1\n",
    "for row, sa_name in enumerate(sa_names):\n",
    "    row += 1\n",
    "    showlegend = False\n",
    "    color = colors[sa_name]\n",
    "    x = st.iterations[sa_name]\n",
    "    y = np.zeros(len(x))\n",
    "    width = st.confidence_intervals_max[sa_name]\n",
    "    lower = y - width / 2\n",
    "    upper = y + width / 2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            showlegend=showlegend,\n",
    "            name = sa_name,\n",
    "            marker=dict(\n",
    "                color=\"rgba({},{},{},{})\".format(\n",
    "                    color[0],\n",
    "                    color[1],\n",
    "                    color[2],\n",
    "                    1,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    showlegend = False\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=lower,\n",
    "            mode=\"lines\",\n",
    "            opacity=opacity,\n",
    "            showlegend=False,\n",
    "            marker=dict(\n",
    "                color=\"rgba({},{},{},{})\".format(\n",
    "                    color[0],\n",
    "                    color[1],\n",
    "                    color[2],\n",
    "                    opacity,\n",
    "                ),\n",
    "            ),\n",
    "            line=dict(width=0),\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=upper,\n",
    "            showlegend=False,\n",
    "            line=dict(width=0),\n",
    "            mode=\"lines\",\n",
    "            fillcolor=\"rgba({},{},{},{})\".format(\n",
    "                color[0],\n",
    "                color[1],\n",
    "                color[2],\n",
    "                opacity,\n",
    "            ),\n",
    "            fill=\"tonexty\",\n",
    "        ),\n",
    "        row=row,\n",
    "        col=col,\n",
    "    )\n",
    "fig.update_xaxes(title='MC iterations')\n",
    "fig.update_yaxes(title='Max confidence interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_salt = S_lsa\n",
    "\n",
    "total = S_salt['Total order']\n",
    "total_argsort = np.argsort(total)[::-1]\n",
    "total_sorted = total[total_argsort]\n",
    "first_sorted = S_salt['First order'][total_argsort]\n",
    "width = st.confidence_intervals['total'][-1,:]\n",
    "width_sorted = width[total_argsort]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(total_sorted)),\n",
    "        y=total_sorted,\n",
    "        mode=\"markers\",\n",
    "        name=\"Total order\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_orange_rgb,\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            symmetric=False,\n",
    "            array=width_sorted/2,\n",
    "            arrayminus=width_sorted/2,\n",
    "            visible=True,\n",
    "            color=color_blue_rgb,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Model inputs')\n",
    "fig.update_yaxes(title='Total order indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_ranked = 23\n",
    "\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "\n",
    "len_tech = model.uncertain_exchange_lengths['tech']\n",
    "where_tech = np.where(parameter_choice_ranked<len_tech)[0]\n",
    "ind_tech = parameter_choice_ranked[where_tech]\n",
    "inf_tech_params = {\n",
    "    where_tech[i]: {\n",
    "        \"type\": \"tech\",\n",
    "        \"param\": model.uncertain_params['tech'][ind_tech[i]]\n",
    "    }\n",
    "    for i in range(len(where_tech))\n",
    "}\n",
    "\n",
    "len_bio = model.uncertain_exchange_lengths['bio']\n",
    "where_bio = np.where(np.logical_and(\n",
    "    parameter_choice_ranked>=len_tech,\n",
    "    parameter_choice_ranked<len_tech+len_bio,\n",
    "))[0]\n",
    "ind_bio = parameter_choice_ranked[where_bio]-len_tech\n",
    "inf_bio_params = {\n",
    "    where_bio[i]: {\n",
    "        \"type\": \"bio\",\n",
    "        \"param\": model.uncertain_params['bio'][ind_bio[i]]\n",
    "    }\n",
    "    for i in range(len(where_bio))\n",
    "}\n",
    "\n",
    "len_cf = model.uncertain_exchange_lengths['cf']\n",
    "where_cf = np.where(np.logical_and(\n",
    "    parameter_choice_ranked>=len_tech+len_bio,\n",
    "    parameter_choice_ranked<len_tech+len_bio+len_cf,\n",
    "))[0]\n",
    "ind_cf = parameter_choice_ranked[where_cf]-len_tech-len_bio\n",
    "inf_cf_params = {\n",
    "    where_cf[i]: {\n",
    "        \"type\": \"cf\",\n",
    "        \"param\": model.uncertain_params['cf'][ind_cf[i]]\n",
    "    }\n",
    "    for i in range(len(where_cf))\n",
    "}\n",
    "\n",
    "params = {**inf_tech_params, **inf_bio_params, **inf_cf_params}\n",
    "params = {k : params[k] for k in sorted(params)}\n",
    "\n",
    "TECH_IND = 0\n",
    "BIO_IND = 2\n",
    "distributions = {\n",
    "    sa.NormalUncertainty.id: 'normal',\n",
    "    sa.LognormalUncertainty.id: 'lognml',\n",
    "    sa.UniformUncertainty.id: 'unifrm',\n",
    "}\n",
    "\n",
    "for rank, dict_ in params.items():\n",
    "    exchange_type = dict_['type']\n",
    "    param = dict_['param']\n",
    "    row = param['row']\n",
    "    col = param['col']\n",
    "    print(\n",
    "        \"{:2d}. total={:5.3f}, {}, amount={:8.5f}, scale={:5.3f}\".format(\n",
    "            rank, \n",
    "            total_sorted[rank],\n",
    "            distributions[param['uncertainty_type']],\n",
    "            param['amount'],\n",
    "            param['scale'],\n",
    "        )\n",
    "    )      \n",
    "    if exchange_type=='tech':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[TECH_IND][row])\n",
    "        act_out = bd.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {}, {} \\n\".format(act_in['name'], act_in['unit'], act_in['location']))\n",
    "    elif exchange_type=='bio':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        act_out = bd.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {} \\n\".format(act_in['name'], act_in['unit']))\n",
    "    elif exchange_type=='cf':\n",
    "        act_in = bd.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        print(\"GWP of:    {} \\n\".format(act_in['name'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ranked = 24\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRanked.graph\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.visualization.plotting import *\n",
    "\n",
    "def plot_hist_val(Y_subset, parameter_choice_ranked):\n",
    "    bin_min = min(val.Y_all)\n",
    "    bin_max = max(val.Y_all)\n",
    "    fig = plot_histogram_Y1_Y2(\n",
    "        val.Y_all,\n",
    "        Y_subset,\n",
    "        bin_min=bin_min,\n",
    "        bin_max=bin_max,\n",
    "        num_bins=60,\n",
    "        trace_name1=\"All parameters vary\",\n",
    "        trace_name2=\"Only influential vary\",\n",
    "        color1=\"#636EFA\",\n",
    "        color2=\"#EF553B\",\n",
    "        opacity=0.65,\n",
    "        xaxes_title_text=val.model_output_name,\n",
    "        showtitle=True,\n",
    "    )\n",
    "    fig.update_yaxes(range=[0,25])\n",
    "    fig.write_image(\n",
    "        val.create_figure_Y_all_Y_inf_histogram_filepath(\n",
    "            parameter_choice_ranked.shape[0], tag, \"pdf\"\n",
    "        ).as_posix()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig_format = [\"pdf\"]\n",
    "spearman_yy = []\n",
    "num_ranked_max = 25\n",
    "num_ranked_arr = np.hstack(\n",
    "    [\n",
    "        np.arange(1,10),\n",
    "        np.arange(10,num_ranked_max,2)\n",
    "    ]\n",
    ")\n",
    "tag = \"TotalRanked.{}\".format(\"graph\")\n",
    "if __name__ == \"__main__\":\n",
    "    for num_ranked in num_ranked_arr:\n",
    "        print(num_ranked)\n",
    "        parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "        Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "        s, _ = spearmanr(val.Y_all, Y_subset)\n",
    "        spearman_yy.append(s)\n",
    "        fig=val.plot_correlation_Y_all_Y_inf(\n",
    "            Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag, fig_format=fig_format,\n",
    "        )\n",
    "        plot_hist_val(Y_subset, parameter_choice_ranked)\n",
    "        \n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=num_ranked_arr,\n",
    "        y=spearman_yy,\n",
    "        mode=\"markers+lines\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_blue_rgb,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Number of varying influential inputs')\n",
    "fig.update_yaxes(title='Spearman correlation between Y_all and Y_inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig_format = [\"pdf\"]\n",
    "spearman_yy = []\n",
    "num_ranked_max = 25\n",
    "num_ranked_arr = np.hstack(\n",
    "    [\n",
    "        np.arange(1,10),\n",
    "        np.arange(10,num_ranked_max,2)\n",
    "    ]\n",
    ")\n",
    "tag = \"TotalRanked.{}\".format(\"protocol\")\n",
    "if __name__ == \"__main__\":\n",
    "    for num_ranked in num_ranked_arr:\n",
    "        print(num_ranked)\n",
    "        parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "        Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked, tag=tag)\n",
    "        s, _ = spearmanr(val.Y_all, Y_subset)\n",
    "        spearman_yy.append(s)\n",
    "        fig=val.plot_correlation_Y_all_Y_inf(\n",
    "            Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag, fig_format=fig_format,\n",
    "        )\n",
    "        plot_hist_val(Y_subset, parameter_choice_ranked)\n",
    "        \n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=num_ranked_arr,\n",
    "        y=spearman_yy,\n",
    "        mode=\"markers+lines\",\n",
    "        showlegend=False,\n",
    "        marker_color = color_blue_rgb,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(title='Number of varying influential inputs')\n",
    "fig.update_yaxes(title='Spearman correlation between Y_all and Y_inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ranked = 9\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "parameter_choice_ranked_inv = np.setdiff1d(np.arange(model.num_params), parameter_choice_ranked)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRankedInv\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked_inv, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_ranked = 23\n",
    "parameter_choice_ranked = parameter_choice_inf[total_argsort][:num_ranked]\n",
    "parameter_choice_ranked_inv = np.setdiff1d(np.arange(model.num_params), parameter_choice_ranked)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"TotalRankedInv\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_ranked_inv, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_ranked.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:protocol-dev-py38]",
   "language": "python",
   "name": "conda-env-protocol-dev-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
