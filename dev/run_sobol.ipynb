{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gsa_framework.test_functions import SobolGstar\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.extended_FAST import eFAST\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     path_base = Path(\n",
    "#         \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "#     )\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # 1. Models\n",
    "    num_params = 1000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 2000\n",
    "    write_dir = path_base / \"sobol_Gstar_model_{}\".format(num_params)\n",
    "    gsa_seed = 3407\n",
    "    sobol_g_star_seed = 345897\n",
    "    validation_seed = 7043\n",
    "    if num_influential == 10:\n",
    "        a = np.array(\n",
    "            [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "            + [9] * (num_params - num_influential)\n",
    "        )\n",
    "        alpha = np.ones(num_params)  # case 2 from Saltelli paper\n",
    "    else:\n",
    "        a = 9 * np.ones(num_params)\n",
    "        a[:num_influential] = np.linspace(0, 4, num_influential, endpoint=True)\n",
    "        alpha = np.ones(num_params)\n",
    "    np.random.seed(sobol_g_star_seed)\n",
    "    delta = np.random.rand(num_params)  # delta doesn't affect input importance\n",
    "    np.random.seed(None)\n",
    "    model = SobolGstar(\n",
    "        num_params=num_params,\n",
    "        num_influential=num_influential,\n",
    "        a=a,\n",
    "        alpha=alpha,\n",
    "        delta=delta,\n",
    "    )\n",
    "    fig_format = []  # can have elements \"pdf\", \"html\", \"pickle\"\n",
    "\n",
    "    num_params_corr_plot = 10\n",
    "    parameter_inds = list(range(num_params_corr_plot)) + list(\n",
    "        range(num_influential, num_influential + num_params_corr_plot)\n",
    "    )\n",
    "\n",
    "    # TODO Choose which GSA to perform\n",
    "    flag_sobol = 0\n",
    "    flag_eFAST = 1\n",
    "    flag_xgboost = 0\n",
    "\n",
    "#     if flag_sobol:\n",
    "#         iterations = 400 * num_params\n",
    "#         gsa = SaltelliSobol(iterations=iterations, model=model, write_dir=write_dir)\n",
    "#         S_dict = gsa.perform_gsa()\n",
    "#         first = S_dict[\"First order\"]\n",
    "#         total = S_dict[\"Total order\"]\n",
    "#         gsa.plot_sa_results(\n",
    "#             S_dict,\n",
    "#             S_dict_analytical=model.S_dict_analytical,\n",
    "#             fig_format=fig_format,\n",
    "#         )\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         val = Validation(\n",
    "#             model=model,\n",
    "#             iterations=iterations_validation,\n",
    "#             seed=validation_seed,\n",
    "#             default_x_rescaled=None,\n",
    "#             write_dir=write_dir,\n",
    "#         )\n",
    "#         tag_total = \"SaltelliTotalIndex\"\n",
    "#         influential_Y_total = val.get_influential_Y_from_gsa(total, num_influential, tag=tag_total)\n",
    "#         tag_first = \"SaltelliFirstIndex\"\n",
    "#         influential_Y_first = val.get_influential_Y_from_gsa(first, num_influential, tag=tag_first)\n",
    "#         t1 = time.time()\n",
    "#         print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "#         # val.plot_correlation_Y_all_Y_inf(\n",
    "#         #     influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "#         # )\n",
    "# #         val.plot_histogram_Y_all_Y_inf(\n",
    "# #             influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "# #         )\n",
    "#         corr_coef_total = np.corrcoef(np.vstack([influential_Y_total, val.Y_all]))[0,1]\n",
    "#         corr_coef_first = np.corrcoef(np.vstack([influential_Y_first, val.Y_all]))[0,1]\n",
    "#         spearman_total, _ = spearmanr(influential_Y_total, val.Y_all)\n",
    "#         spearman_first, _ = spearmanr(influential_Y_first, val.Y_all)\n",
    "#         print(\" \\\n",
    "#              corr_coef_total {} \\n \\\n",
    "#              corr_coef_first {} \\n \\\n",
    "#              spearman_total {} \\n \\\n",
    "#              spearman_first {} \\n\".format(corr_coef_total, corr_coef_first, spearman_total, spearman_first)\n",
    "#         )\n",
    "\n",
    "#         conv = Convergence(\n",
    "#             gsa.filepath_Y,\n",
    "#             gsa.num_params,\n",
    "#             gsa.generate_gsa_indices,\n",
    "#             gsa.gsa_label,\n",
    "#             write_dir,\n",
    "#             num_steps=100,\n",
    "#         )\n",
    "#         conv.run_convergence(parameter_inds=parameter_inds, fig_format=fig_format)\n",
    "\n",
    "    if flag_eFAST:\n",
    "        iterations = 3000 * num_params\n",
    "        M = 4\n",
    "        gsa = eFAST(\n",
    "            M=M, iterations=iterations, model=model, write_dir=write_dir, seed=gsa_seed\n",
    "        )\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        first = S_dict[\"First order\"]\n",
    "        total = S_dict[\"Total order\"]\n",
    "        gsa.plot_sa_results(\n",
    "            S_dict,\n",
    "            S_dict_analytical=model.S_dict_analytical,\n",
    "            fig_format=fig_format,\n",
    "        )\n",
    "\n",
    "        t0 = time.time()\n",
    "        val = Validation(\n",
    "            model=model,\n",
    "            iterations=iterations_validation,\n",
    "            seed=validation_seed,\n",
    "            default_x_rescaled=None,\n",
    "            write_dir=write_dir,\n",
    "        )\n",
    "        tag = \"eFastTotalIndex\"\n",
    "        influential_Y = val.get_influential_Y_from_gsa(total, num_sinfluential, tag=tag)\n",
    "        t1 = time.time()\n",
    "        print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "        val.plot_histogram_Y_all_Y_inf(\n",
    "            influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "        )\n",
    "        \n",
    "        conv = Convergence(\n",
    "            gsa.filepath_Y,\n",
    "            gsa.num_params,\n",
    "            gsa.generate_gsa_indices,\n",
    "            gsa.gsa_label,\n",
    "            write_dir,\n",
    "            num_steps=100,\n",
    "            M=M,\n",
    "        )\n",
    "        conv.run_convergence(\n",
    "            parameter_inds=parameter_inds, fig_format=fig_format\n",
    "        )\n",
    "\n",
    "    if flag_xgboost:\n",
    "        gsa = GradientBoosting(iterations=iterations, model=model, write_dir=write_dir)\n",
    "        S_dict = gsa.perform_gsa()\n",
    "        fscores = S_dict[\"fscores\"]\n",
    "        gsa.plot_sa_results(S_dict, S_boolean=model.S_boolean)\n",
    "        val = Validation(fscores, model, num_influential=model.num_influential)\n",
    "        val.generate_plots(plot_histogram=True, plot_correlation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.extended_FAST import eFAST\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.plotting import histogram_Y1_Y2\n",
    "from gsa_framework.utils import read_hdf5_array\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     path_base = Path(\n",
    "#         \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "#     )\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"Food\" in act[\"name\"]][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 500\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    validation_seed = 7043\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "    \n",
    "    iterations = 2 * num_params\n",
    "    gsa = CorrelationCoefficients(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        seed=gsa_seed,\n",
    "    )\n",
    "#     S_dict = gsa.perform_gsa()\n",
    "    S_dict = gsa.generate_gsa_indices()\n",
    "    pearson = S_dict[\"pearson\"]\n",
    "    spearman = S_dict[\"spearman\"]\n",
    "    gsa.plot_sa_results(S_dict, fig_format=fig_format)\n",
    "\n",
    "    t0 = time.time()\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=None,\n",
    "        write_dir=write_dir,\n",
    "    )\n",
    "    tag = \"SpearmanIndex\"\n",
    "    influential_Y = val.get_influential_Y_from_gsa(\n",
    "        spearman, num_influential, tag=tag\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "    val.plot_histogram_Y_all_Y_inf(\n",
    "        influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run XGBoost LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_framework.lca import LCAModel\n",
    "from gsa_framework.methods.correlations import CorrelationCoefficients\n",
    "from gsa_framework.methods.extended_FAST import eFAST\n",
    "from gsa_framework.methods.saltelli_sobol import SaltelliSobol\n",
    "from gsa_framework.methods.gradient_boosting import GradientBoosting\n",
    "from gsa_framework.validation import Validation\n",
    "from gsa_framework.convergence import Convergence\n",
    "from pathlib import Path\n",
    "import brightway2 as bw\n",
    "import time\n",
    "import numpy as np\n",
    "from gsa_framework.plotting import histogram_Y1_Y2\n",
    "from gsa_framework.utils import read_hdf5_array\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     path_base = Path(\n",
    "#         \"/Users/akim/PycharmProjects/gsa_framework/dev/write_files/paper_gsa/\"\n",
    "#     )\n",
    "    path_base = Path('/data/user/kim_a/paper_gsa/gsa_framework_files')\n",
    "\n",
    "    # LCA model\n",
    "    bw.projects.set_current(\"GSA for paper\")\n",
    "    co = bw.Database(\"CH consumption 1.0\")\n",
    "    act = [act for act in co if \"Food\" in act[\"name\"]][0]\n",
    "    demand = {act: 1}\n",
    "    method = (\"IPCC 2013\", \"climate change\", \"GTP 100a\")\n",
    "\n",
    "    # Define some variables\n",
    "    num_params = 10000\n",
    "    num_influential = num_params // 100\n",
    "    iterations_validation = 500\n",
    "    write_dir = path_base / \"lca_model_{}\".format(num_params)\n",
    "    model = LCAModel(demand, method, write_dir, num_params=num_params)\n",
    "    gsa_seed = 3403\n",
    "    validation_seed = 7043\n",
    "    fig_format = [\"html\", \"pickle\"]\n",
    "\n",
    "    parameter_inds_convergence_plot = [1,2,3]  # TODO choose for convergence\n",
    "\n",
    "    num_boost_round = 200\n",
    "    tuning_parameters = {\n",
    "         'max_depth': 6,  \n",
    "         'eta': 0.1,\n",
    "         'objective': 'reg:squarederror',\n",
    "         'n_jobs': -1,\n",
    "         'refresh_leaf': True,\n",
    "         'subsample': 0.4,\n",
    "         'min_child_weight': 0.5,\n",
    "    }\n",
    "    iterations = 2 * num_params\n",
    "    gsa = GradientBoosting(\n",
    "        iterations=iterations,\n",
    "        model=model,\n",
    "        write_dir=write_dir,\n",
    "        seed=gsa_seed,\n",
    "        tuning_parameters=tuning_parameters,\n",
    "        num_boost_round=num_boost_round,\n",
    "        xgb_model=None,\n",
    "    )\n",
    "    S_dict = gsa.perform_gsa(flag_save_S_dict=True)\n",
    "    fscores = S_dict[\"fscores\"]\n",
    "    gsa.plot_sa_results(\n",
    "        S_dict,\n",
    "        S_boolean=model.S_boolean,\n",
    "        fig_format=fig_format,\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=None,\n",
    "        write_dir=write_dir,\n",
    "    )\n",
    "    tag = \"FscoresIndex\"\n",
    "    influential_Y = val.get_influential_Y_from_gsa(fscores, num_influential, tag=tag)\n",
    "    t1 = time.time()\n",
    "    print(\"Total validation time  -> {:8.3f} s \\n\".format(t1 - t0))\n",
    "    val.plot_histogram_Y_all_Y_inf(\n",
    "        influential_Y, num_influential, tag=tag, fig_format=fig_format\n",
    "    )\n",
    "\n",
    "#     conv = Convergence(\n",
    "#         gsa.filepath_Y,\n",
    "#         gsa.num_params,\n",
    "#         gsa.generate_gsa_indices,\n",
    "#         gsa.gsa_label,\n",
    "#         write_dir,\n",
    "#         num_steps=100,\n",
    "#     )\n",
    "#     conv.run_convergence(\n",
    "#         parameter_inds=parameter_inds,\n",
    "#         fig_format=fig_format,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bw]",
   "language": "python",
   "name": "conda-env-bw-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
