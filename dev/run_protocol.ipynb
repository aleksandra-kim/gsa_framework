{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from gsa_framework.models import LCAModel\n",
    "from gsa_framework.convergence_robustness_validation import Validation\n",
    "from gsa_framework.utils import read_pickle\n",
    "\n",
    "from setups_paper_gwp import setup_lca_model_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = Path('/data/user/kim_a')\n",
    "num_params = None\n",
    "model, write_dir, gsa_seed = setup_lca_model_protocol(\n",
    "    path_base,\n",
    "    num_params=num_params,\n",
    "    write_dir=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Run MC when everything varies, 408k inputs\n",
    "### tech=186k, bio=222k, cf=71 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_uncertain_amounts = np.hstack([\n",
    "    v for v in model.default_uncertain_amounts.values()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iterations_validation = 300\n",
    "validation_seed = 100023423\n",
    "lca_scores_axis_title = r\"$\\text{LCA scores, [kg CO}_2\\text{-eq}]$\"\n",
    "if __name__ == \"__main__\":\n",
    "    val = Validation(\n",
    "        model=model,\n",
    "        iterations=iterations_validation,\n",
    "        seed=validation_seed,\n",
    "        default_x_rescaled=default_uncertain_amounts,\n",
    "        write_dir=write_dir,\n",
    "        model_output_name=lca_scores_axis_title,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run MC after LSA step, where NON-influential are removed,198k inputs\n",
    "### tech=186k, bio=12238, cf=68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lsa = model.write_dir / \"LSA_scores\"\n",
    "path_lsa_include_inds_bio = path_lsa / \"include_inds_bio.pickle\"\n",
    "include_inds_bio = read_pickle(path_lsa_include_inds_bio)\n",
    "path_lsa_include_inds_cf = path_lsa / \"include_inds_cf.pickle\"\n",
    "include_inds_cf = read_pickle(path_lsa_include_inds_cf)\n",
    "\n",
    "include_inds_tech_forX = np.arange(model.uncertain_exchange_lengths['tech'])\n",
    "include_inds_bio_forX  = model.uncertain_exchange_lengths['tech'] + include_inds_bio\n",
    "include_inds_cf_forX   = model.uncertain_exchange_lengths['tech'] + \\\n",
    "                         model.uncertain_exchange_lengths['bio']  + include_inds_cf\n",
    "parameter_choice_rm_noninf = np.hstack(\n",
    "    [include_inds_tech_forX, include_inds_bio_forX, include_inds_cf_forX]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"LocalSA_rm_noninf\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_rm_noninf, tag=tag)\n",
    "    \n",
    "# fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_noninf.shape[0], tag=tag)\n",
    "# fig.show()\n",
    "\n",
    "# fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_noninf.shape[0], tag=tag)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run MC after LSA step, where LOWly influential are removed,\n",
    "10k, 15k and 20k inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure  that the chosen num_params in LCA are appropriate\n",
    "# scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "# num_params_lsa = 10000 #10000\n",
    "# where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "# parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     tag = \"LocalSA_rm_lowinf\"\n",
    "#     Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_rm_lowinf, tag=tag)\n",
    "    \n",
    "# fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()\n",
    "\n",
    "# fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure  that the chosen num_params in LCA are appropriate\n",
    "# scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "# num_params_lsa = 15000 #10000\n",
    "# where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "# parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     tag = \"LocalSA_rm_lowinf\"\n",
    "#     Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_rm_lowinf, tag=tag)\n",
    "    \n",
    "# fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()\n",
    "\n",
    "# fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure  that the chosen num_params in LCA are appropriate\n",
    "scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "num_params_lsa = 20000 #10000\n",
    "where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"LocalSA_rm_lowinf\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_rm_lowinf, tag=tag)\n",
    "    \n",
    "# fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()\n",
    "\n",
    "# fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_rm_lowinf.shape[0], tag=tag)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run MC for GSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "# from dask_jobqueue import SLURMCluster\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_pc = \"merlin_protocol_gsa\"\n",
    "# if 'merlin' in which_pc:\n",
    "#     path_dask_logs = Path('/data/user/kim_a/dask_logs')\n",
    "#     path_dask_logs.mkdir(parents=True, exist_ok=True)\n",
    "#     cluster = SLURMCluster(cores     = 8, \n",
    "#                            memory    ='30GB', \n",
    "#                            walltime  = '10:00:00',\n",
    "#                            interface ='ib0',\n",
    "#                            local_directory = path_dask_logs.as_posix(),\n",
    "#                            log_directory   = path_dask_logs.as_posix(),\n",
    "#                            queue=\"daily\",\n",
    "#                            ) \n",
    "# elif 'local' in which_pc:\n",
    "#     cluster = LocalCluster(memory_limit='7GB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_workers = 20\n",
    "# cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from gsa_framework.models import LCAModel\n",
    "from gsa_framework.convergence_robustness_validation import Validation\n",
    "from gsa_framework.utils import read_pickle\n",
    "\n",
    "from setups_paper_gwp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 20\n",
    "\n",
    "path_base = Path('/data/user/kim_a')\n",
    "num_params = 20000\n",
    "iter_corr = 4*num_params\n",
    "gsa_corr = setup_corr(num_params, iter_corr, setup_lca_model_protocol, path_base)\n",
    "n_workers_corr = n_workers\n",
    "\n",
    "options = {\n",
    "    'corr': {\n",
    "        \"iterations\": iter_corr,\n",
    "        \"n_workers\":  n_workers_corr,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_X_chunks(gsa_corr, n_workers_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute model outputs\n",
    "# task_per_worker = dask.delayed(compute_scores_per_worker)\n",
    "# model_evals = []\n",
    "# for option,dict_ in options.items():\n",
    "#     iterations = dict_[\"iterations\"]\n",
    "#     n_workers = dict_[\"n_workers\"]\n",
    "#     for i in range(n_workers):\n",
    "#         print(option, num_params, iterations, i, n_workers)\n",
    "#         model_eval = task_per_worker(option, num_params, iterations, i, n_workers, setup_lca_model_protocol, path_base)\n",
    "#         model_evals.append(model_eval)\n",
    "# model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perform GSA on 20k parameters\n",
    "### tech=17'199, bio=2'771, cf=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree of linearity = 0.98/1, SRC coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from gsa_framework.utils import read_hdf5_array\n",
    "\n",
    "# X = read_hdf5_array(gsa_corr.filepath_X_rescaled)\n",
    "# Y = generate_model_output_from_chunks(gsa_corr, n_workers_corr)\n",
    "# reg_model = LinearRegression()\n",
    "# reg_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_4x = reg_model.coef_ * np.std(X, axis=0) / np.std(Y)\n",
    "# np.sum(src_4x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_tech = model.uncertain_exchange_lengths['tech']\n",
    "# where_tech = np.where(parameter_choice_rm_lowinf<len_tech)[0]\n",
    "\n",
    "# len_bio = model.uncertain_exchange_lengths['bio']\n",
    "# where_bio = np.where(np.logical_and(\n",
    "#     parameter_choice_rm_lowinf>=len_tech,\n",
    "#     parameter_choice_rm_lowinf<len_tech+len_bio,\n",
    "# ))[0]\n",
    "\n",
    "# len_cf = model.uncertain_exchange_lengths['cf']\n",
    "# where_cf = np.where(np.logical_and(\n",
    "#     parameter_choice_rm_lowinf>=len_tech+len_bio,\n",
    "#     parameter_choice_rm_lowinf<len_tech+len_bio+len_cf,\n",
    "# ))[0]\n",
    "# where_tech.shape, where_bio.shape, where_cf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = gsa_corr.perform_gsa()\n",
    "spearman = S['spearman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = gsa_corr.plot_sa_results({'Spearman': np.abs(spearman)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Run MC with 100 and 50 most influential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "# num_params_lsa = 20000 #10000\n",
    "# where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "# parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "# num_influential = 100\n",
    "# inf_sorted = np.argsort(np.abs(spearman))[::-1]\n",
    "# parameter_choice_inf = parameter_choice_rm_lowinf[inf_sorted[:num_influential]]\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     tag = \"SpearmanIndex\"\n",
    "#     Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf, tag=tag)\n",
    "\n",
    "# # fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "# # fig.show()\n",
    "\n",
    "# # fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = model.get_lsa_scores_pickle(model.write_dir / \"LSA_scores\")\n",
    "num_params_lsa = 20000 #10000\n",
    "where_high_var = model.get_where_high_var(scores_dict, num_params_lsa)\n",
    "parameter_choice_rm_lowinf = parameter_choice_rm_noninf[where_high_var]\n",
    "\n",
    "num_influential = 50\n",
    "inf_spearman = np.sort(np.abs(spearman))[::-1]\n",
    "inf_sorted = np.argsort(np.abs(spearman))[::-1]\n",
    "parameter_choice_inf = parameter_choice_rm_lowinf[inf_sorted[:num_influential]]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tag = \"SpearmanIndex\"\n",
    "    Y_subset = val.get_influential_Y_from_parameter_choice(influential_inputs=parameter_choice_inf, tag=tag)\n",
    "\n",
    "fig=val.plot_correlation_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_subset, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Influential exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import stats_arrays as sa\n",
    "\n",
    "len_tech = model.uncertain_exchange_lengths['tech']\n",
    "where_tech = np.where(parameter_choice_inf<len_tech)[0]\n",
    "ind_tech = parameter_choice_inf[where_tech]\n",
    "inf_tech_params = {\n",
    "    where_tech[i]: {\n",
    "        \"type\": \"tech\",\n",
    "        \"param\": model.uncertain_params['tech'][ind_tech[i]]\n",
    "    }\n",
    "    for i in range(len(where_tech))\n",
    "}\n",
    "\n",
    "len_bio = model.uncertain_exchange_lengths['bio']\n",
    "where_bio = np.where(np.logical_and(\n",
    "    parameter_choice_inf>=len_tech,\n",
    "    parameter_choice_inf<len_tech+len_bio,\n",
    "))[0]\n",
    "ind_bio = parameter_choice_inf[where_bio]-len_tech\n",
    "inf_bio_params = {\n",
    "    where_bio[i]: {\n",
    "        \"type\": \"bio\",\n",
    "        \"param\": model.uncertain_params['bio'][ind_bio[i]]\n",
    "    }\n",
    "    for i in range(len(where_bio))\n",
    "}\n",
    "\n",
    "len_cf = model.uncertain_exchange_lengths['cf']\n",
    "where_cf = np.where(np.logical_and(\n",
    "    parameter_choice_inf>=len_tech+len_bio,\n",
    "    parameter_choice_inf<len_tech+len_bio+len_cf,\n",
    "))[0]\n",
    "ind_cf = parameter_choice_inf[where_cf]-len_tech-len_bio\n",
    "inf_cf_params = {\n",
    "    where_cf[i]: {\n",
    "        \"type\": \"cf\",\n",
    "        \"param\": model.uncertain_params['cf'][ind_cf[i]]\n",
    "    }\n",
    "    for i in range(len(where_cf))\n",
    "}\n",
    "\n",
    "params = {**inf_tech_params, **inf_bio_params, **inf_cf_params}\n",
    "params = {k : params[k] for k in sorted(params)}\n",
    "\n",
    "TECH_IND = 0\n",
    "BIO_IND = 2\n",
    "distributions = {\n",
    "    sa.NormalUncertainty.id: 'normal',\n",
    "    sa.LognormalUncertainty.id: 'lognml',\n",
    "    sa.UniformUncertainty.id: 'unifrm',\n",
    "}\n",
    "\n",
    "for rank, dict_ in params.items():\n",
    "    exchange_type = dict_['type']\n",
    "    param = dict_['param']\n",
    "    row = param['row']\n",
    "    col = param['col']\n",
    "    print(\n",
    "        \"{:2d}. spearman={:5.3f}, {}, amount={:8.5f}, scale={:5.3f}\".format(\n",
    "            rank, \n",
    "            inf_spearman[rank],\n",
    "            distributions[param['uncertainty_type']],\n",
    "            param['amount'],\n",
    "            param['scale'],\n",
    "        )\n",
    "    )      \n",
    "    if exchange_type=='tech':\n",
    "        act_in = bw.get_activity(model.lca.reverse_dict()[TECH_IND][row])\n",
    "        act_out = bw.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {}, {} \\n\".format(act_in['name'], act_in['unit'], act_in['location']))\n",
    "    elif exchange_type=='bio':\n",
    "        act_in = bw.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        act_out = bw.get_activity(model.lca.reverse_dict()[TECH_IND][col])\n",
    "        print(\"act out:    {}, {}\".format(act_out['name'], act_out['location']))\n",
    "        print(\"act  in:    {}, {} \\n\".format(act_in['name'], act_in['unit']))\n",
    "    elif exchange_type=='cf':\n",
    "        act_in = bw.get_activity(model.lca.reverse_dict()[BIO_IND][row])\n",
    "        print(\"GWP of:    {} \\n\".format(act_in['name'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full information on influential params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ei = bd.Database('ecoinvent 3.7.1 cutoff')\n",
    "# onion_row = [act for act in ei if \"onion seedling production, for planting\" in act['name'].lower() \n",
    "#              and 'RoW'==act['location']][0]\n",
    "# onion_nz  = [act for act in ei if \"onion seedling production, for planting\" in act['name'].lower() \n",
    "#              and 'NZ'==act['location']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. LCA scores if std in onions is reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import numpy as np\n",
    "from gsa_framework.models.life_cycle_assessment import LCAModelCall\n",
    "from gsa_framework.utils import read_hdf5_array, write_hdf5_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current(\"GSA for protocol\")\n",
    "co = bd.Database(\"CH consumption 1.0\")\n",
    "demand_act = [act for act in co if \"Food\" in act[\"name\"]]\n",
    "assert len(demand_act) == 1\n",
    "demand_act = demand_act[0]\n",
    "demand = {demand_act: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "\n",
    "bio_to_modify = []\n",
    "for p in params.values():\n",
    "    param = p['param']\n",
    "    if p['type']=='bio' and param['uncertainty_type']==3 and np.allclose(param['scale'], 0.7383766):\n",
    "        bio_to_modify.append(param)\n",
    "bio_to_modify = bio_to_modify[:1]\n",
    "dt = model.lca.bio_params.dtype\n",
    "bio_params_temp = np.array([a for a in model.lca.bio_params], dtype = dt)\n",
    "bio_params_uncertain = model.lca.bio_params[model.lca.bio_params['uncertainty_type']>1]\n",
    "bio_params_modified = np.array([a for a in model.lca.bio_params], dtype = dt)\n",
    "inds = []\n",
    "inds_uncertain = []\n",
    "for b in bio_to_modify:\n",
    "    ind = np.where(np.logical_and(\n",
    "        bio_params_temp['row']==b['row'],\n",
    "        bio_params_temp['col']==b['col'],\n",
    "    ))[0][0]\n",
    "    inds.append(ind)\n",
    "    indu = np.where(np.logical_and(\n",
    "        bio_params_uncertain['row']==b['row'],\n",
    "        bio_params_uncertain['col']==b['col'],\n",
    "    ))[0][0]\n",
    "    inds_uncertain.append(indu)\n",
    "for ind in inds:\n",
    "    bio_params_modified[ind]['loc'] = np.log(bio_params_temp[ind]['loc'])\n",
    "    bio_params_modified[ind]['uncertainty_type'] = 0#sa.LognormalUncertainty.id\n",
    "#     bio_params_modified[ind]['scale'] = 0\n",
    "\n",
    "# iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_params = {\n",
    "    'tech': model.lca.tech_params,\n",
    "    'bio': bio_params_modified,\n",
    "    'cf': model.lca.cf_params,\n",
    "}\n",
    "model2 = LCAModelCall(\n",
    "    demand, \n",
    "    method, \n",
    "    modified_params,\n",
    ")\n",
    "num_params = len(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tag = 'BioId0'\n",
    "fp_Y_narrow = \"/data/user/kim_a/protocol_gsa/arrays/validation.Y.narrow.{}.{}.{}.hdf5\".format(\n",
    "    iterations_validation, validation_seed, tag\n",
    ")\n",
    "fp_Y_narrow = Path(fp_Y_narrow)\n",
    "np.random.seed(validation_seed)\n",
    "X = np.random.rand(iterations_validation, num_params)\n",
    "Xr = model2.rescale(X)\n",
    "if fp_Y_narrow.exists():\n",
    "    Y_narrow = read_hdf5_array(fp_Y_narrow).flatten()\n",
    "else:\n",
    "    Y_narrow = model2(Xr)\n",
    "    write_hdf5_array(Y_narrow, fp_Y_narrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=val.plot_correlation_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=val.plot_correlation_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=val.plot_correlation_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()\n",
    "\n",
    "fig=val.plot_histogram_Y_all_Y_inf(Y_narrow, num_influential=parameter_choice_inf.shape[0], tag=tag)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_Xr = \"/data/user/kim_a/protocol_gsa/arrays/validation.X.rescaled.all.2000.100023423.hdf5\"\n",
    "Xr_ = read_hdf5_array(fp_Xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(Xr[1:], Xr_[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinds = model2.uncertain_exchange_lengths['tech'] + np.array(inds_uncertain)\n",
    "xinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(Xr[:,xinds], Xr_[:,xinds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "arr1 = Xr[:,xinds][:,ii]\n",
    "arr2 = Xr_[:,xinds][:,ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# freq, bins = np.histogram(arr1, bins=range(0, 60, 5))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=arr1,\n",
    "    ),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=arr2,\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio = bd.Database('biosphere3')\n",
    "co2 = [act for act in bio if \"carbon dioxide, from soil or biomass stock\" in act['name'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa = model.lca.bio_params[model.lca.bio_params['row']==1815]\n",
    "aa[aa['uncertainty_type']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Contribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_act = list(model.lca.demand.keys())[0]\n",
    "list_methods = [model.method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from [Chris' notebook](https://github.com/brightway-lca/brightway2/blob/master/notebooks/Contribution%20analysis%20and%20comparison.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_recursive_calculation(activity, lcia_method, lca_obj=None, total_score=None, amount=1, level=0, max_level=3, cutoff=1e-2):\n",
    "    if lca_obj is None:\n",
    "        lca_obj = bc.LCA({activity: amount}, lcia_method)\n",
    "        lca_obj.lci()\n",
    "        lca_obj.lcia()\n",
    "        total_score = lca_obj.score\n",
    "    elif total_score is None:\n",
    "        raise ValueError\n",
    "    else:\n",
    "        lca_obj.redo_lcia({activity: amount})\n",
    "        if abs(lca_obj.score) <= abs(total_score * cutoff):\n",
    "            return\n",
    "    print(\"{}{:4.3f} ({:06.4f}): {:.70}\".format(\"  \" * level, lca_obj.score / total_score, lca_obj.score, str(activity)))\n",
    "    if level < max_level:\n",
    "        for exc in activity.technosphere():\n",
    "            print_recursive_calculation(\n",
    "                activity=exc.input, \n",
    "                lcia_method=lcia_method, \n",
    "                lca_obj=lca_obj, \n",
    "                total_score=total_score, \n",
    "                amount=amount * exc['amount'], \n",
    "                level=level + 1, \n",
    "                max_level=max_level, \n",
    "                cutoff=cutoff\n",
    "            )\n",
    "            \n",
    "# First number is the percentage of the total score, second number is the actual LCA score\n",
    "print_recursive_calculation(demand_act, model.method, max_level=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for activities in the food sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fus = []\n",
    "for exc in demand_act.exchanges():\n",
    "    if exc['type'] != 'production':\n",
    "        list_fus.append({exc['input']: exc['amount']})\n",
    "    \n",
    "bd.calculation_setups['food_sector_contribution_analysis'] = {'inv':list_fus, 'ia':list_methods}\n",
    "myMultiLCA = bc.MultiLCA('food_sector_contribution_analysis')\n",
    "lcia_unit = bd.Method(list_methods[0]).metadata['unit']\n",
    "fus = [bd.get_activity(list(el.keys())[0])['name'][:] for el in list_fus]\n",
    "df = pd.DataFrame(index=fus, columns=[lcia_unit], data=myMultiLCA.results)\n",
    "df['exchange_amount'] = [list(el.values())[0] for el in list_fus]\n",
    "df['exchange_unit'] = [bd.get_activity(list(el.keys())[0])['unit'] for el in list_fus]\n",
    "df.sort_values(lcia_unit, ascending=False, inplace=True)\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(df)\n",
    "\n",
    "\n",
    "# n_exchanges = len(list_fus)\n",
    "n_exchanges = 40\n",
    "df_plot = df.iloc[:n_exchanges]\n",
    "y = df_plot.index.values\n",
    "x = df_plot['kg CO2-Eq'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=x,y=y,orientation='h',)\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=20*n_exchanges,\n",
    "    width=650,\n",
    "    margin=dict(t=0,b=0,l=250,r=0),\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    "    xaxis_title='LCIA scores, [kg CO2-eq]'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:protocol-dev-py38]",
   "language": "python",
   "name": "conda-env-protocol-dev-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
